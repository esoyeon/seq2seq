{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SeqtoSeq_keras_model_Final.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "jaCFgfbPmQLr",
        "jrsAmqlGojuR"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QNfEeMfaKoR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 604
        },
        "outputId": "9650e1f8-8a10-435b-f543-ca0f02637134"
      },
      "source": [
        "!pip install konlpy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting konlpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4MB 1.3MB/s \n",
            "\u001b[?25hCollecting JPype1>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8b/f7/a368401e630f0e390dd0e62c39fb928e5b23741b53c2360ee7d376660927/JPype1-1.0.2-cp36-cp36m-manylinux2010_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 45.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.18.5)\n",
            "Collecting tweepy>=3.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/bb/7c/99d51f80f3b77b107ebae2634108717362c059a41384a1810d13e2429a81/tweepy-3.9.0-py2.py3-none-any.whl\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
            "Collecting beautifulsoup4==4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 12.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.6.20)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Installing collected packages: JPype1, tweepy, colorama, beautifulsoup4, konlpy\n",
            "  Found existing installation: tweepy 3.6.0\n",
            "    Uninstalling tweepy-3.6.0:\n",
            "      Successfully uninstalled tweepy-3.6.0\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed JPype1-1.0.2 beautifulsoup4-4.6.0 colorama-0.4.3 konlpy-0.5.2 tweepy-3.9.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJB4Y6cFv13B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "e89d8f27-93ea-4c95-fd3d-65822c65a4fd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5I8QdfbhnAA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import re\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import pandas as pd\n",
        "import os\n",
        "import unicodedata\n",
        "import urllib3\n",
        "import zipfile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LABpcIl4h36L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "1d822d4d-918e-42d2-c9af-7d34cf2d4fd7"
      },
      "source": [
        "text = pd.read_excel('/content/drive/My Drive/Project/Seq To Seq/kor.xlsx', encoding='CP949')\n",
        "text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mid_sid</th>\n",
              "      <th>ko</th>\n",
              "      <th>en</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>나는 매일 저녁 배트를 만나러 다락방으로 가요.</td>\n",
              "      <td>I go to the attic every evening to meet Bat.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>선생님 이문장이 이해가 안 가요.</td>\n",
              "      <td>Sir, I don't understand this sentence here.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>컴퓨터를 시작하면 시간이 너무 빠르게 가요.</td>\n",
              "      <td>Time flies when you start using the computer.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>나는 오늘 자정에 한국으로 돌아 가요.</td>\n",
              "      <td>I'm going back to Korea today at midnight.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>나는 일어나자마자 화장실에 가요.</td>\n",
              "      <td>I go to bathroom as soon as I wake up.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74995</th>\n",
              "      <td>74996</td>\n",
              "      <td>나의 고민은 학교가 멀어서 통학하기 힘들어.</td>\n",
              "      <td>My worry is commuting to school because it's t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74996</th>\n",
              "      <td>74997</td>\n",
              "      <td>난 지금 내고양이때문에 충분히 힘들어.</td>\n",
              "      <td>I am going under enough difficulties because o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74997</th>\n",
              "      <td>74998</td>\n",
              "      <td>나와 대화가 어려운 것이 많이 힘들어?</td>\n",
              "      <td>Is having difficulties in talking with me too ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74998</th>\n",
              "      <td>74999</td>\n",
              "      <td>하루에 한번 연락하는게 그렇게 힘들어?</td>\n",
              "      <td>Is it that difficult to call once a day?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74999</th>\n",
              "      <td>75000</td>\n",
              "      <td>어린 아이들이 스포츠를 즐기기엔 많이 힘들죠.</td>\n",
              "      <td>It is difficult for young children to enjoy sp...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>75000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       mid_sid  ...                                                 en\n",
              "0            1  ...       I go to the attic every evening to meet Bat.\n",
              "1            2  ...        Sir, I don't understand this sentence here.\n",
              "2            3  ...      Time flies when you start using the computer.\n",
              "3            4  ...         I'm going back to Korea today at midnight.\n",
              "4            5  ...             I go to bathroom as soon as I wake up.\n",
              "...        ...  ...                                                ...\n",
              "74995    74996  ...  My worry is commuting to school because it's t...\n",
              "74996    74997  ...  I am going under enough difficulties because o...\n",
              "74997    74998  ...  Is having difficulties in talking with me too ...\n",
              "74998    74999  ...           Is it that difficult to call once a day?\n",
              "74999    75000  ...  It is difficult for young children to enjoy sp...\n",
              "\n",
              "[75000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcBtawu9h-Mh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b6cfd4a9-8eff-4385-a997-af3e2d88776e"
      },
      "source": [
        "df = text[['ko','en']]\n",
        "\n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(75000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viUcaT8jYzWT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "f3ff774d-f672-420d-caaa-80fc76f61e6d"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ko</th>\n",
              "      <th>en</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>나는 매일 저녁 배트를 만나러 다락방으로 가요.</td>\n",
              "      <td>I go to the attic every evening to meet Bat.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>선생님 이문장이 이해가 안 가요.</td>\n",
              "      <td>Sir, I don't understand this sentence here.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>컴퓨터를 시작하면 시간이 너무 빠르게 가요.</td>\n",
              "      <td>Time flies when you start using the computer.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>나는 오늘 자정에 한국으로 돌아 가요.</td>\n",
              "      <td>I'm going back to Korea today at midnight.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>나는 일어나자마자 화장실에 가요.</td>\n",
              "      <td>I go to bathroom as soon as I wake up.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           ko                                             en\n",
              "0  나는 매일 저녁 배트를 만나러 다락방으로 가요.   I go to the attic every evening to meet Bat.\n",
              "1          선생님 이문장이 이해가 안 가요.    Sir, I don't understand this sentence here.\n",
              "2    컴퓨터를 시작하면 시간이 너무 빠르게 가요.  Time flies when you start using the computer.\n",
              "3       나는 오늘 자정에 한국으로 돌아 가요.     I'm going back to Korea today at midnight.\n",
              "4          나는 일어나자마자 화장실에 가요.         I go to bathroom as soon as I wake up."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTGz8ro8h_9D",
        "colab_type": "text"
      },
      "source": [
        "## 전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtcrwzYHihOY",
        "colab_type": "text"
      },
      "source": [
        "유니코드(Unicode) 문자열은 문자를 Unicode로 취급하기 때문에 영어나 한국어등의 ASCII 문자로 되어있어도 한 개 문자를 하나씩 다룹니다.\n",
        "\n",
        "즉, 일반 문자열은 바이트 단위로 처리 하지만, 유니코드 문자열에서는 문자 단위로 처리하게 됩니다.\n",
        "\n",
        "한글을 글자 깨짐 없이 사용하고 싶은 경우에는 유니코드 문자열을 사용하면 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QD1tTgAiiBXi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unicode_to_ascii(s): \n",
        "  return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "      if unicodedata.category(c) != 'Mn')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0aTBhVeiEOe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_sentence(sent):\n",
        "    # 위에서 구현한 함수를 내부적으로 호출\n",
        "    # sent = unicode_to_ascii()\n",
        "\n",
        "    # 단어와 구두점 사이에 공백을 만듭니다.\n",
        "    # Ex) \"he is a boy.\" => \"he is a boy .\"\n",
        "    sent = re.sub(r\"([?.!,¿])\", r\" \\1\", sent)\n",
        "\n",
        "    # (a-z, A-Z, \".\", \"?\", \"!\", \",\") 이들을 제외하고는 전부 공백으로 변환합니다.\n",
        "    sent = re.sub(r\"[^a-zA-Zㄱ-ㅎㅏ-ㅣ가-힣!.?]+\", r\" \", sent)\n",
        "\n",
        "    sent = re.sub(r\"\\s+\", \" \", sent)\n",
        "    return sent"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaLb5l-yiLhw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "e1d0eb64-dc85-48ec-c764-577153e7b220"
      },
      "source": [
        "# 전처리 테스트\n",
        "# 문자열 앞에 [u]또는 [U]를 붙여주면 유니코드 문자열이 됩니다.\n",
        "\n",
        "kor_sent1 = u\"저녁 먹었어?\"\n",
        "eng_sent1 = u\"Have you had dinner?\"\n",
        "\n",
        "print(preprocess_sentence(eng_sent1))\n",
        "print(preprocess_sentence(kor_sent1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Have you had dinner ?\n",
            "저녁 먹었어 ?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zfjp70HNiNGR",
        "colab_type": "text"
      },
      "source": [
        "- 전체 데이터에서 33,000개의 샘플만 불러오되, 모든 전처리를 수행하는 함수를 만듭니다.   \n",
        "- 또한 훈련 과정에서 교사 강요(Teacher Forcing)을 사용할 예정이므로, 훈련 시 사용할 디코더의 입력 시퀀스와 실제값에 해당되는 출력 시퀀스를 따로 분리하여 저장합니다.   \n",
        "- 입력 시퀀스에는 시작을 의미하는 토큰인 \\<sos\\>를 추가하고, 출력 시퀀스에는 종료를 의미하는 토큰인 \\<eos\\>를 추가합니다  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qHeqtSjf4E-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "988bbec2-4f77-42ec-97b2-0089ed9d3fa3"
      },
      "source": [
        "len(df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "75000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35ARgUb4i7FF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_preprocessed_data(df):\n",
        "    encoder_input, decoder_input, decoder_target = [], [], []\n",
        "    for i in range(len(df)):\n",
        "      src_line = df.iloc[i][0].strip()\n",
        "      tar_line = df.iloc[i][1].strip()\n",
        "\n",
        "      # source 데이터 전처리\n",
        "      src_line_input = [w for w in preprocess_sentence(src_line).split()]\n",
        "\n",
        "      # target 데이터 전처리\n",
        "      tar_line = preprocess_sentence(tar_line)\n",
        "      tar_line_input = [w for w in (\"<sos> \" + tar_line).split()]\n",
        "      tar_line_target = [w for w in (tar_line + \" <eos>\").split()]\n",
        "\n",
        "      encoder_input.append(src_line_input)\n",
        "      decoder_input.append(tar_line_input)\n",
        "      decoder_target.append(tar_line_target)\n",
        "\n",
        "      # if i == num_samples - 1:\n",
        "      #     break\n",
        "\n",
        "    return encoder_input, decoder_input, decoder_target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5SzBBe7jEm2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encoder_input, decoder_input, decoder_target\n",
        "sents_kor_in, sents_eng_in, sents_eng_out = load_preprocessed_data(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ar1600phv-1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "ed9dc056-f919-4d20-af7b-d7804196e358"
      },
      "source": [
        "print(sents_kor_in[-5:])\n",
        "print(sents_eng_in[-5:])\n",
        "print(sents_eng_out[-5:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['나의', '고민은', '학교가', '멀어서', '통학하기', '힘들어', '.'], ['난', '지금', '내고양이때문에', '충분히', '힘들어', '.'], ['나와', '대화가', '어려운', '것이', '많이', '힘들어', '?'], ['하루에', '한번', '연락하는게', '그렇게', '힘들어', '?'], ['어린', '아이들이', '스포츠를', '즐기기엔', '많이', '힘들죠', '.']]\n",
            "[['<sos>', 'My', 'worry', 'is', 'commuting', 'to', 'school', 'because', 'it', 's', 'too', 'far', '.'], ['<sos>', 'I', 'am', 'going', 'under', 'enough', 'difficulties', 'because', 'of', 'my', 'cat', '.'], ['<sos>', 'Is', 'having', 'difficulties', 'in', 'talking', 'with', 'me', 'too', 'hard', 'for', 'you', '?'], ['<sos>', 'Is', 'it', 'that', 'difficult', 'to', 'call', 'once', 'a', 'day', '?'], ['<sos>', 'It', 'is', 'difficult', 'for', 'young', 'children', 'to', 'enjoy', 'sports', '.']]\n",
            "[['My', 'worry', 'is', 'commuting', 'to', 'school', 'because', 'it', 's', 'too', 'far', '.', '<eos>'], ['I', 'am', 'going', 'under', 'enough', 'difficulties', 'because', 'of', 'my', 'cat', '.', '<eos>'], ['Is', 'having', 'difficulties', 'in', 'talking', 'with', 'me', 'too', 'hard', 'for', 'you', '?', '<eos>'], ['Is', 'it', 'that', 'difficult', 'to', 'call', 'once', 'a', 'day', '?', '<eos>'], ['It', 'is', 'difficult', 'for', 'young', 'children', 'to', 'enjoy', 'sports', '.', '<eos>']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTcZzgo-kWZG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 인코딩\n",
        "tokenizer_kor = Tokenizer()\n",
        "tokenizer_kor.fit_on_texts(sents_kor_in)\n",
        "encoder_input = tokenizer_kor.texts_to_sequences(sents_kor_in)\n",
        "\n",
        "tokenizer_eng = Tokenizer(filters=\"\", lower=True)\n",
        "tokenizer_eng.fit_on_texts(sents_eng_in)\n",
        "tokenizer_eng.fit_on_texts(sents_eng_out)\n",
        "decoder_input = tokenizer_eng.texts_to_sequences(sents_eng_in)\n",
        "decoder_target = tokenizer_eng.texts_to_sequences(sents_eng_out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WYeBydik31E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 패딩\n",
        "encoder_input = pad_sequences(encoder_input, padding=\"post\")\n",
        "decoder_input = pad_sequences(decoder_input, padding=\"post\")\n",
        "decoder_target = pad_sequences(decoder_target, padding=\"post\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnqOY1ySk6R9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "97b8ff1b-e600-4cf0-e203-1e837a21bdde"
      },
      "source": [
        "encoder_input.shape, decoder_input.shape, decoder_target.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((75000, 15), (75000, 19), (75000, 19))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPMBqSX1lC6v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fb7fd4c4-d888-4432-ad5c-3b93a3d4f0b1"
      },
      "source": [
        "src_vocab_size = len(tokenizer_kor.word_index) + 1\n",
        "tar_vocab_size = len(tokenizer_eng.word_index) + 1\n",
        "print(\"한국어 단어 집합의 크기 : {:d}, 영어 단어 집합의 크기 : {:d}\".format(src_vocab_size, tar_vocab_size))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "한국어 단어 집합의 크기 : 85237, 영어 단어 집합의 크기 : 19285\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjRNkAR1SIKC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "0267ceb3-6daf-4dea-e08c-5e3923cc4f0d"
      },
      "source": [
        "encoder_input"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[    3,   267,   345, ...,     0,     0,     0],\n",
              "       [ 1991, 29413,  1406, ...,     0,     0,     0],\n",
              "       [ 1180,  6281,   117, ...,     0,     0,     0],\n",
              "       ...,\n",
              "       [  269,  2640,  1001, ...,     0,     0,     0],\n",
              "       [  874,   221, 85235, ...,     0,     0,     0],\n",
              "       [ 1552,  1330,  7706, ...,     0,     0,     0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGBrDW73lNfr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "src_to_index = tokenizer_kor.word_index\n",
        "index_to_src = tokenizer_kor.index_word # 훈련 후 결과 비교할 때 사용\n",
        "\n",
        "tar_to_index = tokenizer_eng.word_index # 훈련 후 예측 과정에서 사용\n",
        "index_to_tar = tokenizer_eng.index_word # 훈련 후 결과 비교할 때 사용"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09io52LElVV3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0db8d749-3bf0-4ade-83e5-fc0375e30033"
      },
      "source": [
        "indices = np.arange(encoder_input.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "print(indices)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  950 48734 18340 ... 50239 15578 17530]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFRwXsBAlj_D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_input = encoder_input[indices]\n",
        "decoder_input = decoder_input[indices]\n",
        "decoder_target = decoder_target[indices]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eME6EYkfllYJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "26dc6529-45b5-4080-fd03-719922341ef3"
      },
      "source": [
        "encoder_input[30997], decoder_input[30997], decoder_target[30997]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([   26, 13546,   419,   240,   872,     1,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0], dtype=int32),\n",
              " array([  2,   4, 164,  98, 519,  17,   7, 347,  25,   1,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0], dtype=int32),\n",
              " array([  4, 164,  98, 519,  17,   7, 347,  25,   1,   3,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0], dtype=int32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwDw4wtQl7oG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a0267c68-ed08-47f4-8845-8d8b70018c26"
      },
      "source": [
        "n_of_val = int(len(df)*0.1)\n",
        "print(n_of_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfLOpFIwmL5T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_input_train = encoder_input[:-n_of_val]\n",
        "decoder_input_train = decoder_input[:-n_of_val]\n",
        "decoder_target_train = decoder_target[:-n_of_val]\n",
        "\n",
        "encoder_input_test = encoder_input[-n_of_val:]\n",
        "decoder_input_test = decoder_input[-n_of_val:]\n",
        "decoder_target_test = decoder_target[-n_of_val:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfS_TRG0mNyy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "a7cf5683-8d6e-45db-b3ad-0e5bff819976"
      },
      "source": [
        "print(encoder_input_train.shape)\n",
        "print(decoder_input_train.shape)\n",
        "print(decoder_target_train.shape)\n",
        "print(encoder_input_test.shape)\n",
        "print(decoder_input_test.shape)\n",
        "print(decoder_target_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(67500, 15)\n",
            "(67500, 19)\n",
            "(67500, 19)\n",
            "(7500, 15)\n",
            "(7500, 19)\n",
            "(7500, 19)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqfRWlQ3SExd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "c3f12ff3-a72f-4fdb-9a13-782a78662608"
      },
      "source": [
        "encoder_input_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   38,    12,  2587, ...,     0,     0,     0],\n",
              "       [   10,  7508,   220, ...,     0,     0,     0],\n",
              "       [  729,    10,    54, ...,     0,     0,     0],\n",
              "       ...,\n",
              "       [  782,    25, 50451, ...,     0,     0,     0],\n",
              "       [  432,  7222, 36075, ...,     0,     0,     0],\n",
              "       [64769,  1881,  4529, ...,     0,     0,     0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaCFgfbPmQLr",
        "colab_type": "text"
      },
      "source": [
        "## 기계 번역기 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7aTnvt8me5m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_Bv_49LWnVP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a6d9a87d-2e72-4afa-c4fd-1996c3a2825f"
      },
      "source": [
        "src_vocab_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "85237"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnK_9Hxfmggb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "latent_dim = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6wrJQvwZp9d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_decoder_tokens = tar_vocab_size\n",
        "num_encoder_tokens = src_vocab_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkLUkZh59Mcg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "outputId": "bb054f4b-e253-4ffd-a1d0-0fe44942b56f"
      },
      "source": [
        "# 인코더 Layer 2개 \n",
        "encoder_inputs = Input(shape=(None,))\n",
        "enc_emb =  Embedding(src_vocab_size, latent_dim)(encoder_inputs) # 임베딩 층\n",
        "enc_masking = Masking(mask_value=0.0)(enc_emb) # 패딩 0은 연산에서 제외\n",
        "e_outputs, h1, c1 = LSTM(latent_dim, return_state=True, return_sequences=True)(enc_masking)\n",
        "encoder_lstm= LSTM(latent_dim, return_state=True, return_sequences=True)\n",
        "_, h2, c2 = encoder_lstm(e_outputs) # 은닉 상태와 셀 상태를 리턴\n",
        "encoder_states = [h1, c1, h2, c2] # 인코더의 은닉 상태와 셀 상태를 저장\n",
        "\n",
        "# 디코더 Layer 2개 \n",
        "decoder_inputs = Input(shape=(None,))\n",
        "dec_emb_layer = Embedding(tar_vocab_size, latent_dim) # 임베딩 층\n",
        "dec_emb = dec_emb_layer(decoder_inputs) # 패딩 0은 연산에서 제외\n",
        "dec_masking = Masking(mask_value=0.0)(dec_emb)\n",
        "\n",
        "# 상태값 리턴을 위해 return_state는 True, 모든 시점에 대해서 단어를 예측하기 위해 return_sequences는 True\n",
        "out_layer1 = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "d_outputs, dh1, dc1 = out_layer1(dec_masking,initial_state= [h1, c1])\n",
        "out_layer2 = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "final, dh2, dc2 = out_layer2(d_outputs, initial_state= [h2, c2])\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(final)\n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, None, 100)    8523700     input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_3 (Embedding)         (None, None, 100)    1928500     input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "masking_2 (Masking)             (None, None, 100)    0           embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "masking_3 (Masking)             (None, None, 100)    0           embedding_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm_4 (LSTM)                   [(None, None, 100),  80400       masking_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_6 (LSTM)                   [(None, None, 100),  80400       masking_3[0][0]                  \n",
            "                                                                 lstm_4[0][1]                     \n",
            "                                                                 lstm_4[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_5 (LSTM)                   [(None, None, 100),  80400       lstm_4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_7 (LSTM)                   [(None, None, 100),  80400       lstm_6[0][0]                     \n",
            "                                                                 lstm_5[0][1]                     \n",
            "                                                                 lstm_5[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 19285)  1947785     lstm_7[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 12,721,585\n",
            "Trainable params: 12,721,585\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FatgA7s2qj0c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
        "callbacks = [\n",
        "             EarlyStopping(monitor ='val_acc', patience = 3),\n",
        "             ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-rpcClm2wpV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ready_callbacks(dir = './ckpt1'):\n",
        "    import os #폴더 생성\n",
        "    checkpoint_dir = dir\n",
        "    if not os.path.exists(checkpoint_dir):\n",
        "        os.makedirs(checkpoint_dir)\n",
        "    callbacks = [\n",
        "        keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=0),\n",
        "        # This callback saves a SavedModel every 100 batches.\n",
        "        # We include the training loss in the folder name.\n",
        "        keras.callbacks.ModelCheckpoint(\n",
        "            filepath=checkpoint_dir + '/ckpt-loss={loss:.2f}',\n",
        "            monitor='val_loss',\n",
        "            save_best_only=True)\n",
        "    ]\n",
        "    return callbacks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFZS94lveHcB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer = 'adam', loss='sparse_categorical_crossentropy', metrics = ['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_ZHC4UV27Mo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 657
        },
        "outputId": "f1770fec-393a-4fbe-8874-83c0cf9863c0"
      },
      "source": [
        "checkpoint_dir = './ckpt5'\n",
        "if not os.path.exists(checkpoint_dir):\n",
        "    os.makedirs(checkpoint_dir)\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(monitor='val_acc', patience=0),   \n",
        "    tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath=checkpoint_dir + '/ckpt2-loss={loss:.4f}'\n",
        "      )\n",
        "    ]\n",
        "history = model.fit(x = [encoder_input_train, decoder_input_train], y = decoder_target_train, \\\n",
        "          validation_data = ([encoder_input_test, decoder_input_test], decoder_target_test),\n",
        "          batch_size = 128, epochs = 20, callbacks = callbacks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "528/528 [==============================] - ETA: 0s - loss: 3.0789 - acc: 0.5422INFO:tensorflow:Assets written to: ./ckpt5/ckpt2-loss=3.0789/assets\n",
            "528/528 [==============================] - 130s 247ms/step - loss: 3.0789 - acc: 0.5422 - val_loss: 2.9709 - val_acc: 0.5501\n",
            "Epoch 2/20\n",
            "528/528 [==============================] - ETA: 0s - loss: 2.8445 - acc: 0.5621INFO:tensorflow:Assets written to: ./ckpt5/ckpt2-loss=2.8445/assets\n",
            "528/528 [==============================] - 130s 246ms/step - loss: 2.8445 - acc: 0.5621 - val_loss: 2.7761 - val_acc: 0.5743\n",
            "Epoch 3/20\n",
            "528/528 [==============================] - ETA: 0s - loss: 2.6610 - acc: 0.5846INFO:tensorflow:Assets written to: ./ckpt5/ckpt2-loss=2.6610/assets\n",
            "528/528 [==============================] - 131s 247ms/step - loss: 2.6610 - acc: 0.5846 - val_loss: 2.6648 - val_acc: 0.5853\n",
            "Epoch 4/20\n",
            "528/528 [==============================] - ETA: 0s - loss: 2.5279 - acc: 0.5970INFO:tensorflow:Assets written to: ./ckpt5/ckpt2-loss=2.5279/assets\n",
            "528/528 [==============================] - 130s 247ms/step - loss: 2.5279 - acc: 0.5970 - val_loss: 2.5840 - val_acc: 0.5924\n",
            "Epoch 5/20\n",
            "528/528 [==============================] - ETA: 0s - loss: 2.4149 - acc: 0.6085INFO:tensorflow:Assets written to: ./ckpt5/ckpt2-loss=2.4149/assets\n",
            "528/528 [==============================] - 131s 247ms/step - loss: 2.4149 - acc: 0.6085 - val_loss: 2.5236 - val_acc: 0.5984\n",
            "Epoch 6/20\n",
            "528/528 [==============================] - ETA: 0s - loss: 2.3144 - acc: 0.6189INFO:tensorflow:Assets written to: ./ckpt5/ckpt2-loss=2.3144/assets\n",
            "528/528 [==============================] - 130s 247ms/step - loss: 2.3144 - acc: 0.6189 - val_loss: 2.4923 - val_acc: 0.6020\n",
            "Epoch 7/20\n",
            "528/528 [==============================] - ETA: 0s - loss: 2.2224 - acc: 0.6293INFO:tensorflow:Assets written to: ./ckpt5/ckpt2-loss=2.2224/assets\n",
            "528/528 [==============================] - 131s 249ms/step - loss: 2.2224 - acc: 0.6293 - val_loss: 2.4567 - val_acc: 0.6055\n",
            "Epoch 8/20\n",
            "528/528 [==============================] - ETA: 0s - loss: 2.1306 - acc: 0.6399INFO:tensorflow:Assets written to: ./ckpt5/ckpt2-loss=2.1306/assets\n",
            "528/528 [==============================] - 132s 249ms/step - loss: 2.1306 - acc: 0.6399 - val_loss: 2.4321 - val_acc: 0.6087\n",
            "Epoch 9/20\n",
            "528/528 [==============================] - ETA: 0s - loss: 2.0401 - acc: 0.6505INFO:tensorflow:Assets written to: ./ckpt5/ckpt2-loss=2.0401/assets\n",
            "528/528 [==============================] - 130s 246ms/step - loss: 2.0401 - acc: 0.6505 - val_loss: 2.4206 - val_acc: 0.6122\n",
            "Epoch 10/20\n",
            "528/528 [==============================] - ETA: 0s - loss: 1.9562 - acc: 0.6604INFO:tensorflow:Assets written to: ./ckpt5/ckpt2-loss=1.9562/assets\n",
            "528/528 [==============================] - 130s 245ms/step - loss: 1.9562 - acc: 0.6604 - val_loss: 2.4174 - val_acc: 0.6132\n",
            "Epoch 11/20\n",
            "528/528 [==============================] - ETA: 0s - loss: 1.8779 - acc: 0.6696INFO:tensorflow:Assets written to: ./ckpt5/ckpt2-loss=1.8779/assets\n",
            "528/528 [==============================] - 129s 245ms/step - loss: 1.8779 - acc: 0.6696 - val_loss: 2.4222 - val_acc: 0.6150\n",
            "Epoch 12/20\n",
            "528/528 [==============================] - ETA: 0s - loss: 1.8050 - acc: 0.6785INFO:tensorflow:Assets written to: ./ckpt5/ckpt2-loss=1.8050/assets\n",
            "528/528 [==============================] - 130s 246ms/step - loss: 1.8050 - acc: 0.6785 - val_loss: 2.4307 - val_acc: 0.6137\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Zb-LjIcQlYl",
        "colab_type": "text"
      },
      "source": [
        "## seq2seq 기계 번역기 동작시키기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skbHidRQ-_91",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 인코더 모델\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "# 디코더 모델 \n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_state_input_h1 = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c1 = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c, \n",
        "                         decoder_state_input_h1, decoder_state_input_c1]\n",
        "\n",
        "# 임베딩 \n",
        "dec_emb2= dec_emb_layer(decoder_inputs)\n",
        "\n",
        "d_o, state_h, state_c = out_layer1(dec_emb2, initial_state=decoder_states_inputs[:2])\n",
        "d_o, state_h1, state_c1 = out_layer2(d_o, initial_state=decoder_states_inputs[-2:])\n",
        "decoder_states = [state_h, state_c, state_h1, state_c1]\n",
        "decoder_outputs = decoder_dense(d_o)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xe8B03tuBTfa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "outputId": "146ea6c3-eabf-400c-db89-8ea4646f95e7"
      },
      "source": [
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs] + decoder_states)\n",
        "\n",
        "decoder_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_9\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_3 (Embedding)         (None, None, 100)    1928500     input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_9 (InputLayer)            [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_10 (InputLayer)           [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_6 (LSTM)                   [(None, None, 100),  80400       embedding_3[2][0]                \n",
            "                                                                 input_9[0][0]                    \n",
            "                                                                 input_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "input_11 (InputLayer)           [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_12 (InputLayer)           [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_7 (LSTM)                   [(None, None, 100),  80400       lstm_6[2][0]                     \n",
            "                                                                 input_11[0][0]                   \n",
            "                                                                 input_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 19285)  1947785     lstm_7[2][0]                     \n",
            "==================================================================================================\n",
            "Total params: 4,037,085\n",
            "Trainable params: 4,037,085\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2po8QN4rWyh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # 입력으로부터 인코더의 상태를 얻음\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    # <SOS>에 해당하는 정수 생성\n",
        "    target_seq = np.zeros((1,4))\n",
        "    target_seq[0, 0] = tar_to_index['<sos>']\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "\n",
        "    # stop_condition이 True가 될 때까지 루프 반복\n",
        "    # 구현의 간소화를 위해서 이 함수는 배치 크기를 1로 가정합니다.\n",
        "    while not stop_condition:\n",
        "        # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
        "        output_tokens, h, c, h1, c1 = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "        # 예측 결과를 단어로 변환\n",
        "        try:\n",
        "          sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "          sampled_char = index_to_tar[sampled_token_index]\n",
        "        except:\n",
        "          sampled_token_index = np.argsort(output_tokens[0, -1, :])[::-1][1]\n",
        "          sampled_char = index_to_tar[sampled_token_index]\n",
        "\n",
        "         # 현재 시점의 예측 단어를 예측 문장에 추가\n",
        "        decoded_sentence += ' '+sampled_char\n",
        "\n",
        "        # <eos>에 도달하거나 정해진 길이를 넘으면 중단.\n",
        "        if (sampled_char == '<eos>' or\n",
        "           len(decoded_sentence) > 50):\n",
        "            stop_condition = True\n",
        "\n",
        "        # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
        "        states_value = [h, c, h1, c1]\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcGLZhsAunlc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
        "def seq2src(input_seq):\n",
        "    temp=''\n",
        "    for i in input_seq:\n",
        "        if (i!=0):\n",
        "            temp = temp + index_to_src[i]+' '\n",
        "    return temp\n",
        "\n",
        "# 번역문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
        "def seq2tar(input_seq):\n",
        "    temp=''\n",
        "    for i in input_seq:\n",
        "        if ((i!=0 and i!=tar_to_index['<sos>']) and i!=tar_to_index['<eos>']):\n",
        "            temp = temp + index_to_tar[i] + ' '\n",
        "    return temp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdofeaFoa_Qw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "724e260b-7947-4f32-824d-ff80b43634bd"
      },
      "source": [
        "states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "# <SOS>에 해당하는 정수 생성\n",
        "target_seq = np.zeros((1,4))\n",
        "target_seq[0, 0] = tar_to_index['<sos>']\n",
        "\n",
        "output_tokens, h, c, h1, c1 = decoder_model.predict([target_seq] + states_value)\n",
        "np.argsort(output_tokens[0, -1, :])[::-1]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([    4,     0,    37, ..., 15704,  6637, 16645])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgwPPJLQWiRy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "outputId": "04cd674a-b322-47e6-b90d-4a9a5da0c7f3"
      },
      "source": [
        "for seq_index in [3,50,100,300,1001]:\n",
        "  input_seq = encoder_input_train[seq_index: seq_index + 1]\n",
        "  decoded_sentence = decode_sequence(input_seq)\n",
        "\n",
        "  print(\"원문 : \",seq2src(encoder_input_train[seq_index]))\n",
        "  print(\"번역문 :\",seq2tar(decoder_input_train[seq_index]))\n",
        "  print(\"예측문 :\",decoded_sentence[:-5])\n",
        "  print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "원문 :  . 얻어요 그걸 요구하고 최선을 항상 그녀는 \n",
            "번역문 : she always demands and gets the best . \n",
            "예측문 :  she she was a good . \n",
            "\n",
            "\n",
            "원문 :  ? 인천이라면서요 곳이 유명한 서식지로도 갈매기 \n",
            "번역문 : isn t incheon famous for seagull s habitat ? \n",
            "예측문 :  are the country of korea ? \n",
            "\n",
            "\n",
            "원문 :  . 싶어 찍고 먼저 제일 주위를 있는 살고 내가 \n",
            "번역문 : i want to take a picture of my surroundings first . \n",
            "예측문 :  in my house is a good time . \n",
            "\n",
            "\n",
            "원문 :  . 해요 나가야 출장을 지금 내가 \n",
            "번역문 : i have to go on a business trip right now . \n",
            "예측문 :  i go to my school . \n",
            "\n",
            "\n",
            "원문 :  . 기원드려요 되시길 성탄절이 가득한 은총이 하느님의 \n",
            "번역문 : i hope you have a christmas filled with the grace of god . \n",
            "예측문 :  i make a lot of the first time . \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}