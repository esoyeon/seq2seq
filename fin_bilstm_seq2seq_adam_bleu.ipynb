{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NH-U4gDZzf9-"
   },
   "source": [
    "## [tensorflow seq2seq](https://www.tensorflow.org/tutorials/text/nmt_with_attention#translate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m34tmTuVzf-C"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import LSTM,Dense,Embedding,Bidirectional,Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "6Zfp9YLQzyrN",
    "outputId": "8dea1b09-5858-4e69-ba28-8a3bfacafa18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "id": "0VMlT4P7zf-N",
    "outputId": "12a64ec9-58e5-4816-e1ce-16e834a024bc",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ko</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>나는 매일 저녁 배트를 만나러 다락방으로 가요.</td>\n",
       "      <td>I go to the attic every evening to meet Bat.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>선생님 이문장이 이해가 안 가요.</td>\n",
       "      <td>Sir, I don't understand this sentence here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>컴퓨터를 시작하면 시간이 너무 빠르게 가요.</td>\n",
       "      <td>Time flies when you start using the computer.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>나는 오늘 자정에 한국으로 돌아 가요.</td>\n",
       "      <td>I'm going back to Korea today at midnight.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>나는 일어나자마자 화장실에 가요.</td>\n",
       "      <td>I go to bathroom as soon as I wake up.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74995</th>\n",
       "      <td>나의 고민은 학교가 멀어서 통학하기 힘들어.</td>\n",
       "      <td>My worry is commuting to school because it's t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74996</th>\n",
       "      <td>난 지금 내고양이때문에 충분히 힘들어.</td>\n",
       "      <td>I am going under enough difficulties because o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74997</th>\n",
       "      <td>나와 대화가 어려운 것이 많이 힘들어?</td>\n",
       "      <td>Is having difficulties in talking with me too ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74998</th>\n",
       "      <td>하루에 한번 연락하는게 그렇게 힘들어?</td>\n",
       "      <td>Is it that difficult to call once a day?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74999</th>\n",
       "      <td>어린 아이들이 스포츠를 즐기기엔 많이 힘들죠.</td>\n",
       "      <td>It is difficult for young children to enjoy sp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               ko                                                 en\n",
       "0      나는 매일 저녁 배트를 만나러 다락방으로 가요.       I go to the attic every evening to meet Bat.\n",
       "1              선생님 이문장이 이해가 안 가요.        Sir, I don't understand this sentence here.\n",
       "2        컴퓨터를 시작하면 시간이 너무 빠르게 가요.      Time flies when you start using the computer.\n",
       "3           나는 오늘 자정에 한국으로 돌아 가요.         I'm going back to Korea today at midnight.\n",
       "4              나는 일어나자마자 화장실에 가요.             I go to bathroom as soon as I wake up.\n",
       "...                           ...                                                ...\n",
       "74995    나의 고민은 학교가 멀어서 통학하기 힘들어.  My worry is commuting to school because it's t...\n",
       "74996       난 지금 내고양이때문에 충분히 힘들어.  I am going under enough difficulties because o...\n",
       "74997       나와 대화가 어려운 것이 많이 힘들어?  Is having difficulties in talking with me too ...\n",
       "74998       하루에 한번 연락하는게 그렇게 힘들어?           Is it that difficult to call once a day?\n",
       "74999   어린 아이들이 스포츠를 즐기기엔 많이 힘들죠.  It is difficult for young children to enjoy sp...\n",
       "\n",
       "[75000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel('/content/drive/My Drive/seq2seq_3조/seq2seq_aihub/kor.xlsx',sheet_name='Sheet1')\n",
    "src = pd.DataFrame(data['ko'])\n",
    "tar = pd.DataFrame(data['en'])\n",
    "df = pd.concat([src, tar],axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MVi7LliIzf-X"
   },
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w1p0vK3hDOsM"
   },
   "outputs": [],
   "source": [
    "# Converts the unicode file to ascii\n",
    "def unicode_to_ascii(s):\n",
    "  return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "      if unicodedata.category(c) != 'Mn')\n",
    "def en_preprocess_sentence(w):\n",
    "  w = unicode_to_ascii(w.lower().strip())\n",
    "  # creating a space between a word and the punctuation following it\n",
    "  # eg: \"he is a boy.\" => \"he is a boy .\"\n",
    "  # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
    "  w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "  w = re.sub(r'[\" \"]+', \" \", w)\n",
    "  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "  w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "  w = w.strip()\n",
    "  # adding a start and an end token to the sentence\n",
    "  # so that the model know when to start and stop predicting.\n",
    "  w = '<start> ' + w + ' <end>'\n",
    "  return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JF6q8DRTDFUN"
   },
   "outputs": [],
   "source": [
    "def ko_preprocess_sentence(w):\n",
    "  # creating a space between a word and the punctuation following it\n",
    "  # eg: \"he is a boy.\" => \"he is a boy .\"\n",
    "  # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
    "  w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "  w = re.sub(r'[\" \"]+', \" \", w)\n",
    "  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "  w = re.sub(r\"[^ㄱ-ㅎㅏ|가-힣?.!,¿]+\", \" \", w)\n",
    "  w = w.strip()\n",
    "  # adding a start and an end token to the sentence\n",
    "  # so that the model know when to start and stop predicting.\n",
    "  w = '<start> ' + w + ' <end>'\n",
    "  return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "icn50xBjzf-Z"
   },
   "outputs": [],
   "source": [
    "def preprocess_sentence(sent):\n",
    "    # 위에서 구현한 함수를 내부적으로 호출\n",
    "    #sent = unicode_to_ascii(sent.lower())\n",
    "\n",
    "    # 단어와 구두점 사이에 공백을 만듭니다.\n",
    "    # Ex) \"he is a boy.\" => \"he is a boy .\"\n",
    "    sent = re.sub(r\"([?.!,¿])\", r\" \\1\", sent)\n",
    "\n",
    "    # (a-z, A-Z, \".\", \"?\", \"!\", \",\") 이들을 제외하고는 전부 공백으로 변환합니다.\n",
    "    sent = re.sub(r\"[^ㄱ-ㅎㅏ|가-힣a-zA-Z!.?]+\", r\" \", sent)\n",
    "    \n",
    "    sent = re.sub(r\"\\s+\", \" \", sent)\n",
    "\n",
    "    sent = '<start> ' + sent + ' <end>'\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BWX6dTEi0poB"
   },
   "outputs": [],
   "source": [
    "# 1. Remove the accents\n",
    "# 2. Clean the sentences\n",
    "# 3. Return word pairs in the format: [KOREAN, ENGLISH]\n",
    "def create_dataset(data):\n",
    "    ko, en = [],[]\n",
    "    for i in range(len(data)):\n",
    "        src_line = data.iloc[i][0].strip()\n",
    "        tar_line = data.iloc[i][1].strip()\n",
    "        \n",
    "        # source 데이터 전처리\n",
    "        kor = [w for w in preprocess_sentence(src_line).split()]\n",
    "        ko.append(kor)\n",
    "        #ko.append(kor[::-1])\n",
    "        \n",
    "       # print(ko)\n",
    "        # target 데이터 전처리\n",
    "        eng = [w for w in preprocess_sentence(tar_line).split()]\n",
    "        en.append(eng)\n",
    "        \n",
    "    return ko,en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "zmWe6l-873Ex",
    "outputId": "19ad963b-2891-4982-a6ae-dee33f9835a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['<start> 나는 매일 저녁 배트를 만나러 다락방으로 가요 . <end>'], ['<start> 선생님 이문장이 이해가 안 가요 . <end>'], ['<start> 컴퓨터를 시작하면 시간이 너무 빠르게 가요 . <end>'], ['<start> 나는 오늘 자정에 한국으로 돌아 가요 . <end>']]\n"
     ]
    }
   ],
   "source": [
    "ko_list = []\n",
    "en_list = []\n",
    "for i in range(4):\n",
    "        src_line = df.iloc[i][0].strip()\n",
    "        tar_line = df.iloc[i][1].strip()\n",
    "        \n",
    "        # source 데이터 전처리\n",
    "        korean = [' '.join(w for w in preprocess_sentence(src_line).split())]\n",
    "        ko_list.append(korean[::-1])\n",
    "        \n",
    "       # print(ko)\n",
    "        # target 데이터 전처리\n",
    "        english = [w for w in preprocess_sentence(tar_line).split()]\n",
    "        en_list.append(english)\n",
    "print(ko_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JazqhrjGzf_s"
   },
   "outputs": [],
   "source": [
    "ko, en = create_dataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "sshq6eMR7jZk",
    "outputId": "d4b81ac1-b1bb-47c8-9189-8b0429510201"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<start>', '하루에', '한번', '연락하는게', '그렇게', '힘들어', '?', '<end>']\n",
      "['<start>', 'Is', 'it', 'that', 'difficult', 'to', 'call', 'once', 'a', 'day', '?', '<end>']\n"
     ]
    }
   ],
   "source": [
    "print(ko[-2])\n",
    "print(en[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mzcr8DTezgAI"
   },
   "outputs": [],
   "source": [
    "def tokenize(lang):\n",
    "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "    lang_tokenizer.fit_on_texts(lang)\n",
    "\n",
    "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,padding='post')\n",
    "\n",
    "    return tensor, lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GqIQKzdZzgAd"
   },
   "outputs": [],
   "source": [
    "def load_dataset(df):\n",
    "  # creating cleaned input, output pairs\n",
    "    inp_lang, targ_lang = create_dataset(df)\n",
    "   # print(inp_lang, targ_lang)\n",
    "    input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
    "    target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
    "\n",
    "    return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kdmObRkzzgA4"
   },
   "outputs": [],
   "source": [
    "# Try experimenting with the size of that dataset\n",
    "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(df)\n",
    "\n",
    "# Calculate max_length of the target tensors\n",
    "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0e6Gw_PYzgBK",
    "outputId": "0c5fc0bf-982d-4229-b5ba-1d155d61aa47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 17) (60000, 20) (15000, 17) (15000, 20)\n"
     ]
    }
   ],
   "source": [
    "# Creating training and validation sets using an 80-20 split\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
    "\n",
    "print(input_tensor_train.shape, target_tensor_train.shape, input_tensor_val.shape, target_tensor_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kowdJAu8zgBc"
   },
   "source": [
    "## tf.data 데이터 셋 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DdW9MJKBzgBd"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_inp_size = len(inp_lang.word_index)+1\n",
    "vocab_tar_size = len(targ_lang.word_index)+1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "oTik0nbQzgBi",
    "outputId": "ef16f03f-09e3-4fdf-b1c9-a2d577eefb7f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 17]), TensorShape([64, 20]))"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mBsbLDtDzgBq"
   },
   "source": [
    "## 인코더 및 디코더 모델 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qxQ1HoDPzgBr"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.bilstm = tf.keras.layers.Bidirectional(LSTM(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,recurrent_initializer='glorot_uniform'))                                       \n",
    "                    \n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state_fh, state_fc, state_bh, state_bc = self.bilstm(x, initial_state = hidden)\n",
    "\n",
    "        return output, state_fh, state_fc, state_bh, state_bc\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return [tf.zeros((self.batch_sz, self.enc_units)) for i in range(4)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "QJkltanmzgCA",
    "outputId": "5f624d97-e9fe-43b5-91ed-46071d1120e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) (64, 17, 2048)\n",
      "Encoder First Hidden state shape: (batch size, units) (64, 1024)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "# sample input\n",
    "encoder_hidden = encoder.initialize_hidden_state()\n",
    "#encoder_output, encoder_fh, encoder_sh, encoder_fc, encoder_sc = encoder(example_input_batch, encoder_hidden)\n",
    "encoder_output, encoder_fh, encoder_fc, encoder_sh, encoder_sc = encoder(example_input_batch, encoder_hidden)\n",
    "\n",
    "#encoder_states = [encoder_output, encoder_hidden]\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(encoder_output.shape))\n",
    "print ('Encoder First Hidden state shape: (batch size, units) {}'.format(encoder_fh.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "LPV6pZi7zgCF",
    "outputId": "2f1fd9f6-c701-4c84-c358-18504d3a6b9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        multiple                  21821440  \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional multiple                  10493952  \n",
      "=================================================================\n",
      "Total params: 32,315,392\n",
      "Trainable params: 32,315,392\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O7XQDOpSzgCM"
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query1, query2, values):\n",
    "        # query hidden state shape == (batch_size, hidden size)\n",
    "        # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # values shape == (batch_size, max_len, hidden size)\n",
    "        # we are doing this to broadcast addition along the time axis to calculate the score\n",
    "        query = Concatenate()([query1, query2])\n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying score to self.V\n",
    "        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "        score = self.V(tf.nn.tanh(\n",
    "            self.W1(query_with_time_axis) + self.W2(values)))\n",
    "\n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "U1Esk-xpzgCR",
    "outputId": "2bf4cb9e-b5ea-4699-ef43-93c8634c3e31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) (64, 2048)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (64, 17, 1)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = BahdanauAttention(10)\n",
    "attention_result, attention_weights = attention_layer(encoder_fh, encoder_sh, encoder_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HALs1PfnzgCo"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.bilstm = tf.keras.layers.Bidirectional(LSTM(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform'))\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        # used for attention\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, fhidden, shidden, fcell, scell, enc_output):\n",
    "        # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "        context_vector, attention_weights = self.attention(fhidden, shidden, enc_output)\n",
    "\n",
    "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "        # passing the concatenated vector to the GRU\n",
    "        output, state_fh, state_fc, state_sh, state_sc = self.bilstm(x)\n",
    "\n",
    "        # output shape == (batch_size * 1, hidden_size)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "        # output shape == (batch_size, vocab)\n",
    "        x = self.fc(output)\n",
    "\n",
    "        return x, state_fh, state_fc, state_sh, state_sc, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Gi5AhP4XzgCy",
    "outputId": "a4173055-b672-4ca9-f813-4b9b88b55095"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (64, 19286)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "decoder_output, _, _,_,_, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
    "                                      encoder_fh, encoder_fc, encoder_sh, encoder_sc, encoder_output)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(decoder_output.shape))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "jY_y15FgzgC6",
    "outputId": "8936159e-e1fd-4419-d76f-d8b7507dc436",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      multiple                  4937216   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection multiple                  27271168  \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              multiple                  39517014  \n",
      "_________________________________________________________________\n",
      "bahdanau_attention_1 (Bahdan multiple                  4197377   \n",
      "=================================================================\n",
      "Total params: 75,922,775\n",
      "Trainable params: 75,922,775\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7_-QZv4DzgDN"
   },
   "source": [
    "## 옵티마이저 및 손실 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8MLrrEH3zgDW"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "#optimizer = tf.keras.optimizers.SGD(learning_rate=0.75)\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qcS8qLb-zgDn"
   },
   "outputs": [],
   "source": [
    "# 검사 점(오브젝트 기반 저장)\n",
    "checkpoint_dir = '/content/drive/My Drive/seq2seq_3조/fin_bilstm_adam_model/training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qVGWQJYVzgDw"
   },
   "source": [
    "## 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RfeCUrkGzgDx"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden_fh, enc_hidden_fc, enc_hidden_sh,enc_hidden_sc  = encoder(inp, enc_hidden)\n",
    "\n",
    "        dec_hidden_fh = enc_hidden_fh\n",
    "        dec_hidden_sh = enc_hidden_sh\n",
    "        dec_hidden_fc = enc_hidden_fc\n",
    "        dec_hidden_sc = enc_hidden_sc\n",
    "\n",
    "        dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "        # Teacher forcing - feeding the target as the next input\n",
    "        for t in range(1, targ.shape[1]):\n",
    "          # passing enc_output to the decoder\n",
    "            predictions, dec_hidden_fh,dec_hidden_fc,dec_hidden_sh,dec_hidden_sc, _ = decoder(dec_input, dec_hidden_fh,dec_hidden_fc,dec_hidden_sh,dec_hidden_sc, enc_output)\n",
    "\n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "          # using teacher forcing\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i6HRqoJlzgD2"
   },
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "# EPOCHS = 10\n",
    "\n",
    "# for epoch in tqdm(range(EPOCHS)):\n",
    "#     start = time.time()\n",
    "\n",
    "#     enc_hidden = encoder.initialize_hidden_state()\n",
    "#     total_loss = 0\n",
    "\n",
    "#     for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "#         batch_loss = train_step(inp, targ, enc_hidden)\n",
    "#         total_loss += batch_loss\n",
    "\n",
    "#         if batch % 100 == 0:\n",
    "#             print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "#                                                        batch,\n",
    "#                                                        batch_loss.numpy()))\n",
    "#   # saving (checkpoint) the model every 2 epochs\n",
    "#     if (epoch + 1) % 2 == 0:\n",
    "#         checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "#     print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "#                                       total_loss / steps_per_epoch))\n",
    "#     print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Zw6hJtZoDnKK",
    "outputId": "7790faae-4503-4af8-91fe-811026b0ab79"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 5.4731\n",
      "Epoch 1 Batch 100 Loss 3.0433\n",
      "Epoch 1 Batch 200 Loss 2.8230\n",
      "Epoch 1 Batch 300 Loss 2.7668\n",
      "Epoch 1 Batch 400 Loss 2.6739\n",
      "Epoch 1 Batch 500 Loss 2.5467\n",
      "Epoch 1 Batch 600 Loss 2.5713\n",
      "Epoch 1 Batch 700 Loss 2.5986\n",
      "Epoch 1 Batch 800 Loss 2.5634\n",
      "Epoch 1 Batch 900 Loss 2.4656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 1/10 [10:03<1:30:29, 603.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss 2.7400\n",
      "Time taken for 1 epoch 603.2559950351715 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 2.3383\n",
      "Epoch 2 Batch 100 Loss 2.2705\n",
      "Epoch 2 Batch 200 Loss 2.3576\n",
      "Epoch 2 Batch 300 Loss 2.3599\n",
      "Epoch 2 Batch 400 Loss 2.3494\n",
      "Epoch 2 Batch 500 Loss 2.2759\n",
      "Epoch 2 Batch 600 Loss 2.1337\n",
      "Epoch 2 Batch 700 Loss 2.3930\n",
      "Epoch 2 Batch 800 Loss 2.1616\n",
      "Epoch 2 Batch 900 Loss 2.3651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 2/10 [19:40<1:19:23, 595.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss 2.2845\n",
      "Time taken for 1 epoch 577.2708413600922 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 1.9881\n",
      "Epoch 3 Batch 100 Loss 2.0224\n",
      "Epoch 3 Batch 200 Loss 2.0149\n",
      "Epoch 3 Batch 300 Loss 2.0844\n",
      "Epoch 3 Batch 400 Loss 2.0229\n",
      "Epoch 3 Batch 500 Loss 2.0367\n",
      "Epoch 3 Batch 600 Loss 1.8935\n",
      "Epoch 3 Batch 700 Loss 1.8987\n",
      "Epoch 3 Batch 800 Loss 1.9988\n",
      "Epoch 3 Batch 900 Loss 1.8921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 3/10 [29:12<1:08:38, 588.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss 1.9833\n",
      "Time taken for 1 epoch 571.9818737506866 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 1.7099\n",
      "Epoch 4 Batch 100 Loss 1.7197\n",
      "Epoch 4 Batch 200 Loss 1.6914\n",
      "Epoch 4 Batch 300 Loss 1.6955\n",
      "Epoch 4 Batch 400 Loss 1.6263\n",
      "Epoch 4 Batch 500 Loss 1.6066\n",
      "Epoch 4 Batch 600 Loss 1.5919\n",
      "Epoch 4 Batch 700 Loss 1.6539\n",
      "Epoch 4 Batch 800 Loss 1.6125\n",
      "Epoch 4 Batch 900 Loss 1.5756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 4/10 [38:48<58:28, 584.74s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss 1.6709\n",
      "Time taken for 1 epoch 576.1596217155457 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 1.2885\n",
      "Epoch 5 Batch 100 Loss 1.4164\n",
      "Epoch 5 Batch 200 Loss 1.2814\n",
      "Epoch 5 Batch 300 Loss 1.3712\n",
      "Epoch 5 Batch 400 Loss 1.4097\n",
      "Epoch 5 Batch 500 Loss 1.3955\n",
      "Epoch 5 Batch 600 Loss 1.3871\n",
      "Epoch 5 Batch 700 Loss 1.3048\n",
      "Epoch 5 Batch 800 Loss 1.3404\n",
      "Epoch 5 Batch 900 Loss 1.2988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 5/10 [48:19<48:22, 580.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Loss 1.3564\n",
      "Time taken for 1 epoch 570.8396944999695 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 1.0000\n",
      "Epoch 6 Batch 100 Loss 0.9773\n",
      "Epoch 6 Batch 200 Loss 1.0128\n",
      "Epoch 6 Batch 300 Loss 1.0437\n",
      "Epoch 6 Batch 400 Loss 1.1314\n",
      "Epoch 6 Batch 500 Loss 1.0959\n",
      "Epoch 6 Batch 600 Loss 1.0223\n",
      "Epoch 6 Batch 700 Loss 1.1109\n",
      "Epoch 6 Batch 800 Loss 1.1014\n",
      "Epoch 6 Batch 900 Loss 1.0536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 6/10 [57:54<38:35, 578.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Loss 1.0493\n",
      "Time taken for 1 epoch 574.5876441001892 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.8040\n",
      "Epoch 7 Batch 100 Loss 0.7183\n",
      "Epoch 7 Batch 200 Loss 0.7307\n",
      "Epoch 7 Batch 300 Loss 0.6773\n",
      "Epoch 7 Batch 400 Loss 0.8124\n",
      "Epoch 7 Batch 500 Loss 0.7492\n",
      "Epoch 7 Batch 600 Loss 0.7662\n",
      "Epoch 7 Batch 700 Loss 0.8998\n",
      "Epoch 7 Batch 800 Loss 0.7856\n",
      "Epoch 7 Batch 900 Loss 0.8349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 7/10 [1:07:25<28:49, 576.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Loss 0.7748\n",
      "Time taken for 1 epoch 571.3867156505585 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.5093\n",
      "Epoch 8 Batch 100 Loss 0.5431\n",
      "Epoch 8 Batch 200 Loss 0.5077\n",
      "Epoch 8 Batch 300 Loss 0.4778\n",
      "Epoch 8 Batch 400 Loss 0.5028\n",
      "Epoch 8 Batch 500 Loss 0.6102\n",
      "Epoch 8 Batch 600 Loss 0.6265\n",
      "Epoch 8 Batch 700 Loss 0.5612\n",
      "Epoch 8 Batch 800 Loss 0.5246\n",
      "Epoch 8 Batch 900 Loss 0.5531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 8/10 [1:17:01<19:12, 576.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Loss 0.5439\n",
      "Time taken for 1 epoch 575.9085574150085 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.3655\n",
      "Epoch 9 Batch 100 Loss 0.3205\n",
      "Epoch 9 Batch 200 Loss 0.3136\n",
      "Epoch 9 Batch 300 Loss 0.3343\n",
      "Epoch 9 Batch 400 Loss 0.3921\n",
      "Epoch 9 Batch 500 Loss 0.4379\n",
      "Epoch 9 Batch 600 Loss 0.4003\n",
      "Epoch 9 Batch 700 Loss 0.3113\n",
      "Epoch 9 Batch 800 Loss 0.3890\n",
      "Epoch 9 Batch 900 Loss 0.3952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 9/10 [1:26:34<09:35, 575.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Loss 0.3614\n",
      "Time taken for 1 epoch 573.2372214794159 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.2251\n",
      "Epoch 10 Batch 100 Loss 0.2573\n",
      "Epoch 10 Batch 200 Loss 0.2021\n",
      "Epoch 10 Batch 300 Loss 0.2271\n",
      "Epoch 10 Batch 400 Loss 0.2072\n",
      "Epoch 10 Batch 500 Loss 0.2519\n",
      "Epoch 10 Batch 600 Loss 0.2221\n",
      "Epoch 10 Batch 700 Loss 0.2555\n",
      "Epoch 10 Batch 800 Loss 0.2121\n",
      "Epoch 10 Batch 900 Loss 0.2175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [1:36:12<00:00, 577.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Loss 0.2292\n",
      "Time taken for 1 epoch 578.0985381603241 sec\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 어순 그대로 인풋\n",
    "from tqdm import tqdm\n",
    "EPOCHS = 10\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    start = time.time()\n",
    "\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                       batch,\n",
    "                                                       batch_loss.numpy()))\n",
    "  # saving (checkpoint) the model every 2 epochs\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HKJ3SRZZzgEI"
   },
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                         maxlen=max_length_inp,\n",
    "                                                         padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "    result = ''\n",
    "\n",
    "    hidden = [tf.zeros((1, units)) for i in range(4)]\n",
    "    enc_out, enc_hidden_fh,enc_hidden_sh, enc_hidden_fc,enc_hidden_sc = encoder(inputs, hidden)\n",
    "\n",
    "    dec_hidden_fh = enc_hidden_fh\n",
    "    dec_hidden_sh = enc_hidden_sh\n",
    "    dec_hidden_fc = enc_hidden_fc\n",
    "    dec_hidden_sc = enc_hidden_sc\n",
    "    #dec_input = tf.expand_dims([targ_lang.word_index['<start> ']], 0)\n",
    "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
    "\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden_fh,dec_hidden_fc,dec_hidden_sh,dec_hidden_sc, attention_weights = decoder(dec_input,\n",
    "                                                         dec_hidden_fh,dec_hidden_fc,dec_hidden_sh,dec_hidden_sc,\n",
    "                                                         enc_out)\n",
    "\n",
    "        # storing the attention weights to plot later on\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "        result += targ_lang.index_word[predicted_id] + ' '\n",
    "\n",
    "        #if targ_lang.index_word[predicted_id] == ' <end>':\n",
    "        if targ_lang.index_word[predicted_id] == '<end>':\n",
    "            return result, sentence\n",
    "\n",
    "        # the predicted ID is fed back into the model\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bt2r4U7rzgEY"
   },
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "    result, sentence = evaluate(sentence)\n",
    "\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "\n",
    "    # attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    # plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "P5QkHJryUXVd",
    "outputId": "04e86a69-5b2c-442f-aaae-15a438c7983f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ihaYB4nCzgEc"
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# checkpoint.restore(tf.train.latest_checkpoint('/content/drive/My Drive/seq2seq_3조/bilstm_adam_model/training_checkpoints'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Vrs2QJ7hU8is",
    "outputId": "7395b9be-9829-4bd3-80fa-def1075bdfb1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fcdee215eb8>"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "plnAatuvzgE7",
    "outputId": "64084d4f-527a-49f8-937d-bd4983da35f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> 어린 아이들이 스포츠를 즐기기엔 많이 힘들죠 . <end>\n",
      "Predicted translation: sports diet . <end> \n"
     ]
    }
   ],
   "source": [
    "translate('어린 아이들이 스포츠를 즐기기엔 많이 힘들죠.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "yeCf66QKZ5kx",
    "outputId": "2b3ee1dd-d484-4f06-c55e-111c0c707320"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> 나의 고민은 학교가 멀어서 통학하기 힘들어 . <end>\n",
      "Predicted translation: goal is to the best . <end> \n"
     ]
    }
   ],
   "source": [
    "translate('나의 고민은 학교가 멀어서 통학하기 힘들어.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "gFyYKBsbZ5tq",
    "outputId": "4af3886b-37a1-432f-b2f8-290f03518bfb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> 나는 학교에 간다 . <end>\n",
      "Predicted translation: school . <end> \n"
     ]
    }
   ],
   "source": [
    "$translate('나는 학교에 간다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "tDUEWNd6Z5ba",
    "outputId": "31ef9353-f400-475a-c946-92b9d701163e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> 어린 아이들이 스포츠를 즐기기엔 많이 힘들죠 <end>\n",
      "Predicted translation: sports park . <end> \n"
     ]
    }
   ],
   "source": [
    "translate('어린 아이들이 스포츠를 즐기기엔 많이 힘들죠')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "icJz25UgaKjQ",
    "outputId": "73894ee0-c1a8-48cf-9d1f-c1ab1039c5c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> 아빠는 밥 먹었어 ? <end>\n",
      "Predicted translation: eat ? <end> \n"
     ]
    }
   ],
   "source": [
    "translate('아빠는 밥 먹었어?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "zao5UMlOaKYJ",
    "outputId": "28a9dc2b-1082-4322-940f-5ef0ac619be5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> 하루에 한번 연락하는 게 그렇게 힘들어 ? <end>\n",
      "Predicted translation: for a while ? <end> \n"
     ]
    }
   ],
   "source": [
    "translate('하루에 한번 연락하는 게 그렇게 힘들어?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3CmMXy6fT-uy"
   },
   "outputs": [],
   "source": [
    "def translate_4_bleu(sentence):\n",
    "    result, sentence = evaluate(sentence)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "hZdvA4qrUE13",
    "outputId": "7f734a1d-1121-4086-eb12-62f03e0420cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['나의 고민은 학교가 멀어서 통학하기 힘들어.',\n",
       " '난 지금 내고양이때문에 충분히 힘들어.',\n",
       " '나와 대화가 어려운 것이 많이 힘들어?',\n",
       " '하루에 한번 연락하는게 그렇게 힘들어?',\n",
       " '어린 아이들이 스포츠를 즐기기엔 많이 힘들죠.']"
      ]
     },
     "execution_count": 108,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테스트셋 가져오기\n",
    "en_list = list(df['en'].loc[60000:])\n",
    "en_list[-5:]\n",
    "ko_list =list(df['ko'].loc[60000:])\n",
    "ko_list[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VG6tMp6_TbW3"
   },
   "outputs": [],
   "source": [
    "# bleu\n",
    "import nltk.translate.bleu_score as bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "def sentences_to_bleu(ref, pred):\n",
    "  \"\"\"\n",
    "  ref : 참고용 타겟 문장(학습용 영어 문장)\n",
    "  pred : 예측 문장(번역 결과)\n",
    "  \"\"\"\n",
    "  smoothie = SmoothingFunction().method4\n",
    "  return bleu.sentence_bleu(ref, pred, smoothing_function=smoothie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "8YzBpEVaIi_w",
    "outputId": "f23f2e19-ad4a-437f-fd2a-566701b57b75"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'sports diet . '"
      ]
     },
     "execution_count": 130,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate_4_bleu(ko_list[-1])[:-6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373,
     "referenced_widgets": [
      "74e1ec0daa0042b09515792dabb51bb3",
      "d5d003301490448ba692aaa47fb551ed",
      "256fbb2c62304638b2d0a7cd9551ca14",
      "1379c52caf3043c3a77129227752aeb3",
      "66643c432c23498cbc45762b4df65730",
      "13d880cd8a4f4f3699d158c1a8e6a345",
      "217acbec03f14266856b0985a734463e",
      "2f864742fa6a4c6795f370d1455c2f99",
      "a5f3a849bdfa4c38930a8cbf67692774",
      "ea2eb8530ef4480080b6decb6e8abd0f",
      "a6c90f9345c5415798832bcd652d8fd8",
      "b07012fe963c429091d77834b2d71876",
      "b9fc2213de8143b68e65856f1f095ee7",
      "c66cd8ac4ff74c25a1e4f1c98057abd6",
      "e9abe6d7d57a400b97945236d28e63db",
      "038c711369c94559868d2220f5d48091"
     ]
    },
    "colab_type": "code",
    "id": "IW5cZS7owVS0",
    "outputId": "c3c9e050-1f4b-4321-80ff-979602ca6aed"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74e1ec0daa0042b09515792dabb51bb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15000.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5f3a849bdfa4c38930a8cbf67692774",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14999.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "reference = []\n",
    "pred = []\n",
    "bleu_score = []\n",
    "err_cnt = 0\n",
    "for i in tqdm_notebook(range(len(ko_list))):\n",
    "  try: \n",
    "    decoded_sentence = translate_4_bleu(ko_list[i])[:-6]\n",
    "    reference.append(en_list[i])\n",
    "    pred.append(decoded_sentence)\n",
    "    #bleu_score.append(bleu.sentence_bleu(list(map(lambda ref: ref.split(), reference)),decoded_sentence.split()))\n",
    "    #bleu_score.append(bleu.sentence_bleu(reference[i],pred[i]))\n",
    "\n",
    "  except KeyError:\n",
    "    err_cnt += 1\n",
    "    print(err_cnt)\n",
    "    pass\n",
    "for i in tqdm_notebook(range(0,len(pred))):\n",
    "  bleu_score.append(bleu.sentence_bleu([reference[i].split()], pred[i].split()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "oWu4kvqdKQ88",
    "outputId": "668f9550-f0c2-4af6-fcba-46d4676e4426"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.668740304976422,\n",
       " 0.7598356856515925,\n",
       " 0.6389431042462724,\n",
       " 0.8408964152537145,\n",
       " 0.7598356856515925]"
      ]
     },
     "execution_count": 143,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "h-992w3xKBs0",
    "outputId": "2eeb333f-8758-49a2-afba-6806d603e725"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8498912392268879"
      ]
     },
     "execution_count": 139,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu.sentence_bleu(reference[0],pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "TTKr6as-9cIW",
    "outputId": "1edaa098-3fd6-4cdc-c509-765aac1a22be"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['speed into the plate . ',\n",
       " 'kakao talk . ',\n",
       " 'to give up my major . ',\n",
       " 'land . ',\n",
       " 'are different . ']"
      ]
     },
     "execution_count": 136,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "iTcwnd8g7LE6",
    "outputId": "d0f2ebfe-2f5b-4bb4-b322-3e3f2788fcad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I decided the colors to be yellow, black and white.',\n",
       " 'I have notified the expense report on KakaoTalk.',\n",
       " 'After having these thoughts, I decided to give up my major.',\n",
       " 'I visited London, Belgium, Netherlands, and France.',\n",
       " 'So I thought of methods in different way.']"
      ]
     },
     "execution_count": 137,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "001xEDBsxdA2",
    "outputId": "2d0e4292-348e-4176-96f1-9a4f5a441ebf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000\n"
     ]
    }
   ],
   "source": [
    "print(len(ko_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "rpZg1IV0nip-",
    "outputId": "41eb8a43-4e29-4911-8b2e-ef612b90fc81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9166068134248218, 0.8408964152537145, 0.8722877451005959, 0.7487402156832422, 0.8545740127924681, 0.9306048591020996, 0.9253911813809743, 0.8408964152537145, 0.9306048591020996, 0.9740037464252967, 1.0, 0.9554427922043668, 0.8408964152537145, 0.9306048591020996, 0.9036020036098448, 0.9036020036098448, 0.9709835434146469, 0.8408964152537145, 0.8335516383402117, 0.9193227152249185]\n"
     ]
    }
   ],
   "source": [
    "print(bleu_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CHav5BvTUBWG"
   },
   "outputs": [],
   "source": [
    "# bleu 평균\n",
    "sum = 0\n",
    "for i in range(len(bleu_score)):\n",
    "  sum += bleu_score[i]\n",
    "\n",
    "avg = sum / len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OKdxqBLxNshW",
    "outputId": "c738ddfb-6e55-4fd3-8388-8d41dbb77017"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.729040904039391"
      ]
     },
     "execution_count": 149,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bu7tnvzUN4LN"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "fin_bilstm_seq2seq_adam.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "038c711369c94559868d2220f5d48091": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1379c52caf3043c3a77129227752aeb3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2f864742fa6a4c6795f370d1455c2f99",
      "placeholder": "​",
      "style": "IPY_MODEL_217acbec03f14266856b0985a734463e",
      "value": " 15000/15000 [14:18&lt;00:00, 17.47it/s]"
     }
    },
    "13d880cd8a4f4f3699d158c1a8e6a345": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "217acbec03f14266856b0985a734463e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "256fbb2c62304638b2d0a7cd9551ca14": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_13d880cd8a4f4f3699d158c1a8e6a345",
      "max": 15000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_66643c432c23498cbc45762b4df65730",
      "value": 15000
     }
    },
    "2f864742fa6a4c6795f370d1455c2f99": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "66643c432c23498cbc45762b4df65730": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "74e1ec0daa0042b09515792dabb51bb3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_256fbb2c62304638b2d0a7cd9551ca14",
       "IPY_MODEL_1379c52caf3043c3a77129227752aeb3"
      ],
      "layout": "IPY_MODEL_d5d003301490448ba692aaa47fb551ed"
     }
    },
    "a5f3a849bdfa4c38930a8cbf67692774": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a6c90f9345c5415798832bcd652d8fd8",
       "IPY_MODEL_b07012fe963c429091d77834b2d71876"
      ],
      "layout": "IPY_MODEL_ea2eb8530ef4480080b6decb6e8abd0f"
     }
    },
    "a6c90f9345c5415798832bcd652d8fd8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c66cd8ac4ff74c25a1e4f1c98057abd6",
      "max": 14999,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b9fc2213de8143b68e65856f1f095ee7",
      "value": 14999
     }
    },
    "b07012fe963c429091d77834b2d71876": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_038c711369c94559868d2220f5d48091",
      "placeholder": "​",
      "style": "IPY_MODEL_e9abe6d7d57a400b97945236d28e63db",
      "value": " 14999/14999 [00:27&lt;00:00, 537.50it/s]"
     }
    },
    "b9fc2213de8143b68e65856f1f095ee7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "c66cd8ac4ff74c25a1e4f1c98057abd6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d5d003301490448ba692aaa47fb551ed": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e9abe6d7d57a400b97945236d28e63db": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ea2eb8530ef4480080b6decb6e8abd0f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
