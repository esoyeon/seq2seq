{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1Fhe80XUnXer"
   },
   "source": [
    "## [tensorflow seq2seq](https://www.tensorflow.org/tutorials/text/nmt_with_attention#translate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TlsBo1AYnXet"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "colab_type": "code",
    "id": "h2vMRooTnbqQ",
    "outputId": "567a82ec-e26d-469f-9bf8-7972785f217d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "id": "UsaJGoSKnXez",
    "outputId": "ceb1e2ff-deab-4543-b8e1-52098bd8b659",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ko</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>나는 매일 저녁 배트를 만나러 다락방으로 가요.</td>\n",
       "      <td>I go to the attic every evening to meet Bat.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>선생님 이문장이 이해가 안 가요.</td>\n",
       "      <td>Sir, I don't understand this sentence here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>컴퓨터를 시작하면 시간이 너무 빠르게 가요.</td>\n",
       "      <td>Time flies when you start using the computer.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>나는 오늘 자정에 한국으로 돌아 가요.</td>\n",
       "      <td>I'm going back to Korea today at midnight.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>나는 일어나자마자 화장실에 가요.</td>\n",
       "      <td>I go to bathroom as soon as I wake up.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74995</th>\n",
       "      <td>나의 고민은 학교가 멀어서 통학하기 힘들어.</td>\n",
       "      <td>My worry is commuting to school because it's t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74996</th>\n",
       "      <td>난 지금 내고양이때문에 충분히 힘들어.</td>\n",
       "      <td>I am going under enough difficulties because o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74997</th>\n",
       "      <td>나와 대화가 어려운 것이 많이 힘들어?</td>\n",
       "      <td>Is having difficulties in talking with me too ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74998</th>\n",
       "      <td>하루에 한번 연락하는게 그렇게 힘들어?</td>\n",
       "      <td>Is it that difficult to call once a day?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74999</th>\n",
       "      <td>어린 아이들이 스포츠를 즐기기엔 많이 힘들죠.</td>\n",
       "      <td>It is difficult for young children to enjoy sp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               ko                                                 en\n",
       "0      나는 매일 저녁 배트를 만나러 다락방으로 가요.       I go to the attic every evening to meet Bat.\n",
       "1              선생님 이문장이 이해가 안 가요.        Sir, I don't understand this sentence here.\n",
       "2        컴퓨터를 시작하면 시간이 너무 빠르게 가요.      Time flies when you start using the computer.\n",
       "3           나는 오늘 자정에 한국으로 돌아 가요.         I'm going back to Korea today at midnight.\n",
       "4              나는 일어나자마자 화장실에 가요.             I go to bathroom as soon as I wake up.\n",
       "...                           ...                                                ...\n",
       "74995    나의 고민은 학교가 멀어서 통학하기 힘들어.  My worry is commuting to school because it's t...\n",
       "74996       난 지금 내고양이때문에 충분히 힘들어.  I am going under enough difficulties because o...\n",
       "74997       나와 대화가 어려운 것이 많이 힘들어?  Is having difficulties in talking with me too ...\n",
       "74998       하루에 한번 연락하는게 그렇게 힘들어?           Is it that difficult to call once a day?\n",
       "74999   어린 아이들이 스포츠를 즐기기엔 많이 힘들죠.  It is difficult for young children to enjoy sp...\n",
       "\n",
       "[75000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel('/content/drive/My Drive/seq2seq_3조/seq2seq_aihub/kor.xlsx',sheet_name='Sheet1')\n",
    "src = pd.DataFrame(data['ko'])\n",
    "tar = pd.DataFrame(data['en'])\n",
    "df = pd.concat([src, tar],axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QdJGGcO5nXe6"
   },
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yQ3ghuI54yBT"
   },
   "outputs": [],
   "source": [
    " # Converts the unicode file to ascii\n",
    "def unicode_to_ascii(s):\n",
    "  return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "      if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "\n",
    "def en_preprocess_sentence(w):\n",
    "  w = unicode_to_ascii(w.lower().strip())\n",
    "\n",
    "  # creating a space between a word and the punctuation following it\n",
    "  # eg: \"he is a boy.\" => \"he is a boy .\"\n",
    "  # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
    "  w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "  w = re.sub(r'[\" \"]+', \" \", w)\n",
    "\n",
    "  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "  w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "\n",
    "  w = w.strip()\n",
    "\n",
    "  # adding a start and an end token to the sentence\n",
    "  # so that the model know when to start and stop predicting.\n",
    "  w = '<start> ' + w + ' <end>'\n",
    "  return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GNyZecuw5JyB"
   },
   "outputs": [],
   "source": [
    "def ko_preprocess_sentence(w):\n",
    "  # creating a space between a word and the punctuation following it\n",
    "  # eg: \"he is a boy.\" => \"he is a boy .\"\n",
    "  # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
    "  w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "  w = re.sub(r'[\" \"]+', \" \", w)\n",
    "\n",
    "  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "  w = re.sub(r\"[^ㄱ-ㅎㅏ|가-힣?.!,¿]+\", \" \", w)\n",
    "\n",
    "  w = w.strip()\n",
    "\n",
    "  # adding a start and an end token to the sentence\n",
    "  # so that the model know when to start and stop predicting.\n",
    "  w = '<start> ' + w + ' <end>'\n",
    "  return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NBBymGdqnXe7"
   },
   "outputs": [],
   "source": [
    "def preprocess_sentence(sent):\n",
    "    # 위에서 구현한 함수를 내부적으로 호출\n",
    "    #sent = unicode_to_ascii(sent.lower())\n",
    "\n",
    "    # 단어와 구두점 사이에 공백을 만듭니다.\n",
    "    # Ex) \"he is a boy.\" => \"he is a boy .\"\n",
    "    sent = re.sub(r\"([?.!,¿])\", r\" \\1\", sent)\n",
    "\n",
    "    # (a-z, A-Z, \".\", \"?\", \"!\", \",\") 이들을 제외하고는 전부 공백으로 변환합니다.\n",
    "    sent = re.sub(r\"[^ㄱ-ㅎㅏ|가-힣a-zA-Z!.?]+\", r\" \", sent)\n",
    "    \n",
    "    sent = re.sub(r\"\\s+\", \" \", sent)\n",
    "\n",
    "    sent = '<start> ' + sent + ' <end>'\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "hNcmla0anXe_",
    "outputId": "e737ea65-3615-4114-d805-3329ccb71081",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> 컴퓨터를 시작하면 시간이 너무 빠르게 가요 . <end>\n",
      "<start> Time flies when you start using the computer . <end>\n"
     ]
    }
   ],
   "source": [
    "# 전처리 테스트\n",
    "# ko_sent = u\"너 저녁 먹었어?\"\n",
    "# en_sent = u\"Have you had dinner?\"\n",
    "print(preprocess_sentence(df.iloc[2][0]))\n",
    "print(preprocess_sentence(df.iloc[2][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AU-lNbPrnXfI"
   },
   "outputs": [],
   "source": [
    "# 1. Remove the accents\n",
    "# 2. Clean the sentences\n",
    "# 3. Return word pairs in the format: [KOREAN, ENGLISH]\n",
    "def create_dataset(data):\n",
    "    ko, en = [],[]\n",
    "    for i in range(len(data)):\n",
    "        src_line = data.iloc[i][0].strip()\n",
    "        tar_line = data.iloc[i][1].strip()\n",
    "        \n",
    "        # source 데이터 전처리\n",
    "        kor = [w for w in preprocess_sentence(src_line).split()]\n",
    "        #ko.append(kor[::-1])\n",
    "        ko.append(kor)\n",
    "        \n",
    "       # print(ko)\n",
    "        # target 데이터 전처리\n",
    "        eng = [w for w in preprocess_sentence(tar_line).split()]\n",
    "        en.append(eng)\n",
    "        \n",
    "    return ko,en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L7ZgT3WhnXfS"
   },
   "outputs": [],
   "source": [
    "ko, en = create_dataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "2EhZvb4mnXfU",
    "outputId": "7769bc16-2798-4998-9da8-d8e844585475",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<start>', '급한', '일이', '있어서', '손님', '만나러', '가요', '.', '<end>']\n",
      "['<start>', 'I', 'm', 'meeting', 'a', 'guest', 'for', 'urgent', 'matters', '.', '<end>']\n"
     ]
    }
   ],
   "source": [
    "print(ko[10])\n",
    "print(en[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h4dxasM_nXfX"
   },
   "outputs": [],
   "source": [
    "def tokenize(lang):\n",
    "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "    lang_tokenizer.fit_on_texts(lang)\n",
    "\n",
    "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,padding='post')\n",
    "\n",
    "    return tensor, lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ObTg8_YvnXfa"
   },
   "outputs": [],
   "source": [
    "def load_dataset(df):\n",
    "  # creating cleaned input, output pairs\n",
    "    inp_lang, targ_lang = create_dataset(df)\n",
    "    input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
    "    target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
    "\n",
    "    return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UD64NvsUnXfe"
   },
   "outputs": [],
   "source": [
    "# Try experimenting with the size of that dataset\n",
    "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(df)\n",
    "\n",
    "# Calculate max_length of the target tensors\n",
    "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "uYtCU8OJnXfh",
    "outputId": "e1b9893c-d213-4718-eb2e-14869ee58019"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 17) (60000, 20) (15000, 17) (15000, 20)\n"
     ]
    }
   ],
   "source": [
    "# Creating training and validation sets using an 80-20 split\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
    "\n",
    "\n",
    "print(input_tensor_train.shape, target_tensor_train.shape, input_tensor_val.shape, target_tensor_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P83h5zhznXfl"
   },
   "outputs": [],
   "source": [
    "def convert(lang, tensor):\n",
    "    for t in tensor:\n",
    "        if t!=0:\n",
    "            print (\"%d ----> %s\" % (t, lang.index_word[t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "colab_type": "code",
    "id": "-BzleS94nXfo",
    "outputId": "4a2f3ff8-484d-405d-d85c-36ac63a6ac99",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Language; index to word mapping\n",
      "1 ----> <start>\n",
      "5 ----> 나는\n",
      "1057 ----> 방금\n",
      "1658 ----> 인보이스를\n",
      "58466 ----> 어카운팅\n",
      "10523 ----> 팀에게\n",
      "341 ----> 주었어요\n",
      "3 ----> .\n",
      "2 ----> <end>\n",
      "\n",
      "Target Language; index to word mapping\n",
      "1 ----> <start>\n",
      "4 ----> i\n",
      "98 ----> just\n",
      "404 ----> gave\n",
      "5 ----> the\n",
      "14910 ----> invoive\n",
      "6 ----> to\n",
      "5 ----> the\n",
      "2925 ----> accounting\n",
      "331 ----> team\n",
      "3 ----> .\n",
      "2 ----> <end>\n"
     ]
    }
   ],
   "source": [
    "print (\"Input Language; index to word mapping\")\n",
    "convert(inp_lang, input_tensor_train[0])\n",
    "print ()\n",
    "print (\"Target Language; index to word mapping\")\n",
    "convert(targ_lang, target_tensor_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_G1zb9UqnXfq"
   },
   "source": [
    "## tf.data 데이터 셋 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7PzmEF6SnXfq"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 128\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_inp_size = len(inp_lang.word_index)+1\n",
    "vocab_tar_size = len(targ_lang.word_index)+1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "cmx9j4ptnXfs",
    "outputId": "c2780ba6-8cdc-4035-8d1e-b058febc95e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([128, 17]), TensorShape([128, 20]))"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3QyKn5HqnXfv"
   },
   "source": [
    "## 인코더 및 디코더 모델 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YH_hBJRJnXfv"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "\n",
    "        #self.lstm = tf.keras.layers.LSTM(self.enc_units,return_sequences=True,\n",
    "        #                            return_state=True)\n",
    "                                       \n",
    "                    \n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state = hidden)\n",
    "        return output, state\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "7ovq-wNvnXfx",
    "outputId": "c84c2ab7-f049-41ca-d2aa-46f66891d7d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) (128, 17, 1024)\n",
      "Encoder Hidden state shape: (batch size, units) (128, 1024)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "# sample input\n",
    "encoder_hidden = encoder.initialize_hidden_state()\n",
    "encoder_output, encoder_hidden = encoder(example_input_batch, encoder_hidden)\n",
    "\n",
    "encoder_states = [encoder_output, encoder_hidden]\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(encoder_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(encoder_hidden.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "colab_type": "code",
    "id": "G0hi_Ha5nXf0",
    "outputId": "f4a1e04f-a930-4560-dba8-8146ab1e2bfb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        multiple                  21821440  \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    multiple                  3938304   \n",
      "=================================================================\n",
      "Total params: 25,759,744\n",
      "Trainable params: 25,759,744\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KHBttQJ8nXf2"
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        # query hidden state shape == (batch_size, hidden size)\n",
    "        # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # values shape == (batch_size, max_len, hidden size)\n",
    "        # we are doing this to broadcast addition along the time axis to calculate the score\n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying score to self.V\n",
    "        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "        score = self.V(tf.nn.tanh(\n",
    "            self.W1(query_with_time_axis) + self.W2(values)))\n",
    "\n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "P_aevVSOnXf4",
    "outputId": "96c274ab-9876-4943-b8ee-856e50c054a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) (128, 1024)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (128, 17, 1)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = BahdanauAttention(10)\n",
    "attention_result, attention_weights = attention_layer(encoder_hidden, encoder_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2hI1hhZqnXf7"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        # used for attention\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, hidden, enc_output):\n",
    "        # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "\n",
    "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "        # passing the concatenated vector to the GRU\n",
    "        output, state = self.gru(x)\n",
    "\n",
    "        # output shape == (batch_size * 1, hidden_size)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "        # output shape == (batch_size, vocab)\n",
    "        x = self.fc(output)\n",
    "\n",
    "        return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "NyoPonuAnXf_",
    "outputId": "14533ff6-7f90-4874-8ae7-ac7896036df5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (128, 19286)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
    "                                      encoder_hidden, encoder_output)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(decoder_output.shape))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "colab_type": "code",
    "id": "vOjJ3WQVnXgB",
    "outputId": "70a92ace-5e35-4cc2-b8b8-75a499cde4fb",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      multiple                  4937216   \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  multiple                  7084032   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              multiple                  19768150  \n",
      "_________________________________________________________________\n",
      "bahdanau_attention_1 (Bahdan multiple                  2100225   \n",
      "=================================================================\n",
      "Total params: 33,889,623\n",
      "Trainable params: 33,889,623\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UaRjKLRFnXgD"
   },
   "source": [
    "## 옵티마이저 및 손실 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nsrdBABmnXgD"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "#optimizer = tf.keras.optimizers.SGD(learning_rate=0.75)\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PfC_i9F8nXgG"
   },
   "outputs": [],
   "source": [
    "# 검사 점(오브젝트 기반 저장)\n",
    "checkpoint_dir = '/content/drive/My Drive/seq2seq_3조/gru_adam_model/gru_training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kyPTWlwInXgI"
   },
   "source": [
    "## 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "raPFv34anXgI"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "        dec_hidden = enc_hidden\n",
    "\n",
    "        dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "        # Teacher forcing - feeding the target as the next input\n",
    "        for t in range(1, targ.shape[1]):\n",
    "          # passing enc_output to the decoder\n",
    "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "\n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "          # using teacher forcing\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "DuukyljXnXgK",
    "outputId": "f53ae240-3671-4f5f-cdb5-f0d4ef954d62"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 5.5810\n",
      "Epoch 1 Batch 100 Loss 3.1276\n",
      "Epoch 1 Batch 200 Loss 2.9818\n",
      "Epoch 1 Batch 300 Loss 2.8650\n",
      "Epoch 1 Batch 400 Loss 2.7685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 1/10 [03:47<34:09, 227.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss 3.0112\n",
      "Time taken for 1 epoch 227.6706464290619 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 2.6662\n",
      "Epoch 2 Batch 100 Loss 2.6235\n",
      "Epoch 2 Batch 200 Loss 2.5739\n",
      "Epoch 2 Batch 300 Loss 2.5020\n",
      "Epoch 2 Batch 400 Loss 2.3438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 2/10 [07:22<29:51, 223.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss 2.5264\n",
      "Time taken for 1 epoch 215.1669671535492 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 2.4163\n",
      "Epoch 3 Batch 100 Loss 2.4258\n",
      "Epoch 3 Batch 200 Loss 2.3046\n",
      "Epoch 3 Batch 300 Loss 2.2887\n",
      "Epoch 3 Batch 400 Loss 2.2073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 3/10 [10:56<25:45, 220.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss 2.3023\n",
      "Time taken for 1 epoch 213.56847596168518 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 2.1418\n",
      "Epoch 4 Batch 100 Loss 2.0780\n",
      "Epoch 4 Batch 200 Loss 2.1388\n",
      "Epoch 4 Batch 300 Loss 2.1981\n",
      "Epoch 4 Batch 400 Loss 2.1035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 4/10 [14:32<21:55, 219.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss 2.1258\n",
      "Time taken for 1 epoch 215.69131350517273 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 1.9267\n",
      "Epoch 5 Batch 100 Loss 1.9109\n",
      "Epoch 5 Batch 200 Loss 1.9111\n",
      "Epoch 5 Batch 300 Loss 1.9855\n",
      "Epoch 5 Batch 400 Loss 1.9085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 5/10 [18:05<18:08, 217.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Loss 1.9440\n",
      "Time taken for 1 epoch 213.79107284545898 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 1.8058\n",
      "Epoch 6 Batch 100 Loss 1.8177\n",
      "Epoch 6 Batch 200 Loss 1.7394\n",
      "Epoch 6 Batch 300 Loss 1.7548\n",
      "Epoch 6 Batch 400 Loss 1.7305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 6/10 [21:43<14:29, 217.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Loss 1.7582\n",
      "Time taken for 1 epoch 217.18131041526794 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 1.5155\n",
      "Epoch 7 Batch 100 Loss 1.5605\n",
      "Epoch 7 Batch 200 Loss 1.5591\n",
      "Epoch 7 Batch 300 Loss 1.5315\n",
      "Epoch 7 Batch 400 Loss 1.5081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 7/10 [25:18<10:50, 216.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Loss 1.5645\n",
      "Time taken for 1 epoch 214.9904818534851 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 1.3364\n",
      "Epoch 8 Batch 100 Loss 1.3575\n",
      "Epoch 8 Batch 200 Loss 1.3327\n",
      "Epoch 8 Batch 300 Loss 1.3134\n",
      "Epoch 8 Batch 400 Loss 1.3420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 8/10 [28:55<07:13, 216.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Loss 1.3658\n",
      "Time taken for 1 epoch 217.05326533317566 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 1.1587\n",
      "Epoch 9 Batch 100 Loss 1.1872\n",
      "Epoch 9 Batch 200 Loss 1.2148\n",
      "Epoch 9 Batch 300 Loss 1.1408\n",
      "Epoch 9 Batch 400 Loss 1.2444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 9/10 [32:30<03:36, 216.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Loss 1.1729\n",
      "Time taken for 1 epoch 214.96300649642944 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.9912\n",
      "Epoch 10 Batch 100 Loss 0.9577\n",
      "Epoch 10 Batch 200 Loss 1.0080\n",
      "Epoch 10 Batch 300 Loss 0.9766\n",
      "Epoch 10 Batch 400 Loss 1.0218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [36:06<00:00, 216.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Loss 0.9918\n",
      "Time taken for 1 epoch 216.7000834941864 sec\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "EPOCHS = 10\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    start = time.time()\n",
    "\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                       batch,\n",
    "                                                       batch_loss.numpy()))\n",
    "  # saving (checkpoint) the model every 2 epochs\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IORqwqEJnXgN"
   },
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "  attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
    "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                         maxlen=max_length_inp,\n",
    "                                                         padding='post')\n",
    "  inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "  result = ''\n",
    "\n",
    "  hidden = [tf.zeros((1, units))]\n",
    "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "  dec_hidden = enc_hidden\n",
    "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
    "\n",
    "  for t in range(max_length_targ):\n",
    "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                         dec_hidden,\n",
    "                                                         enc_out)\n",
    "\n",
    "    # storing the attention weights to plot later on\n",
    "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "    attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "    result += targ_lang.index_word[predicted_id] + ' '\n",
    "\n",
    "    if targ_lang.index_word[predicted_id] == '<end>':\n",
    "      return result, sentence\n",
    "\n",
    "    # the predicted ID is fed back into the model\n",
    "    dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "  return result, sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cotyEGcwnXgR"
   },
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "    result, sentence = evaluate(sentence)\n",
    "\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "\n",
    "    # attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    # plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wWIuJfrXiiWX"
   },
   "outputs": [],
   "source": [
    "def translate_4_bleu(sentence):\n",
    "    result, sentence = evaluate(sentence)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "fbUWZyJvnXgT",
    "outputId": "187ef0c6-6eda-4aec-e8ce-3240880809eb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f7d2e4aaa58>"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restoring the latest checkpoint in checkpoint_dir\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "TXMBqtAwnXgV",
    "outputId": "a6762f3b-25b7-4ad4-a302-64eba5bbfd56"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'what is the type of japan ? <end> '"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate_4_bleu('어디야?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "khb4Sz_GHa1T",
    "outputId": "509910ea-dec7-4266-dde4-1e33b169e3a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> 나의 고민은 학교가 멀어서 통학하기 힘들어 . <end>\n",
      "Predicted translation: my voice of my work is turning off the school students . <end> \n"
     ]
    }
   ],
   "source": [
    "translate('나의 고민은 학교가 멀어서 통학하기 힘들어.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "RqHt6YaEuY1L",
    "outputId": "7845c43c-1202-4e11-f502-129359f2da13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> 몇 시야 ? <end>\n",
      "Predicted translation: what is the closest ? <end> \n"
     ]
    }
   ],
   "source": [
    "translate('몇 시야?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "Rcs9KC2vZ4pE",
    "outputId": "89e31be1-07cd-421d-a1da-32a8d95a91bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> 나는 학교에 간다 <end>\n",
      "Predicted translation: i will do my father s work at the school . <end> \n"
     ]
    }
   ],
   "source": [
    "translate('나는 학교에 간다')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "MeMsskbaGrqG",
    "outputId": "e1106348-e68e-44c6-ef94-edb3f245f538"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> 어린 아이들이 스포츠를 즐기기엔 많이 힘들죠 . <end>\n",
      "Predicted translation: it is hard to play children to play sports than the game . <end> \n"
     ]
    }
   ],
   "source": [
    "translate('어린 아이들이 스포츠를 즐기기엔 많이 힘들죠.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "QrdL6ma_bJjY",
    "outputId": "70e98c36-335d-4d2a-8a18-4b61992b7226"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> 아빠는 밥 먹었어 ? <end>\n",
      "Predicted translation: shall i ate it with a meal with a while ? <end> \n"
     ]
    }
   ],
   "source": [
    "translate('아빠는 밥 먹었어?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "HhuBc_B-G_yw",
    "outputId": "77c84544-c39e-46af-9f50-6991479883b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> 하루에 한번 연락하는게 그렇게 힘들어 ? <end>\n",
      "Predicted translation: is it ok to call it right away ? <end> \n"
     ]
    }
   ],
   "source": [
    "translate('하루에 한번 연락하는게 그렇게 힘들어?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6knfbSvMdO2S"
   },
   "source": [
    "## BLEU Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gq3-vSbZeJ5J"
   },
   "outputs": [],
   "source": [
    "df.to_csv('ko_en.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "id": "Et_fl7Q8dRkC",
    "outputId": "28533703-559c-4f39-c974-55ec5af1a77f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it is hard to play children to play sports than the game . \n",
      "0.30576902884505114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 4-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "import nltk.translate.bleu_score as bleu\n",
    "\n",
    "# df = pd.read_csv('/content/ko_en.csv')\n",
    "# ko, en = df['ko'], df['en']\n",
    "\n",
    "result, sentence = evaluate('어린 아이들이 스포츠를 즐기기엔 많이 힘들죠.')\n",
    "candidate = result[:-6]\n",
    "reference = ['It is difficult for young children to enjoy sports.', 'It is hard to enjoy sports for young people']\n",
    "print(candidate)\n",
    "\n",
    "print(bleu.sentence_bleu(list(map(lambda ref: ref.split(), reference)),candidate.split()))\n",
    "# NLTK 패키지 구현되어져 있는 코드로 계산한 BLEU 점수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "id": "L8mKewqeJJOo",
    "outputId": "93dd768f-a4b6-4f2d-9d2e-cbadcd891355"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"My worry is commuting to school because it's too far.\",\n",
       " 'I am going under enough difficulties because of my cat.',\n",
       " 'Is having difficulties in talking with me too hard for you?',\n",
       " 'Is it that difficult to call once a day?',\n",
       " 'It is difficult for young children to enjoy sports.']"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_list = list(df['en'].loc[59999:])\n",
    "en_list[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "id": "7oHVgUsvJdG4",
    "outputId": "227ff2e0-3bdd-4d69-b2c9-f77e8d40bde8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['나의 고민은 학교가 멀어서 통학하기 힘들어.',\n",
       " '난 지금 내고양이때문에 충분히 힘들어.',\n",
       " '나와 대화가 어려운 것이 많이 힘들어?',\n",
       " '하루에 한번 연락하는게 그렇게 힘들어?',\n",
       " '어린 아이들이 스포츠를 즐기기엔 많이 힘들죠.']"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ko_list =list(df['ko'].loc[59999:])\n",
    "ko_list[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wu32sPRbfBRN"
   },
   "outputs": [],
   "source": [
    "import nltk.translate.bleu_score as bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "def sentences_to_bleu(ref, pred):\n",
    "  \"\"\"\n",
    "  ref : 참고용 타겟 문장(학습용 영어 문장)\n",
    "  pred : 예측 문장(번역 결과)\n",
    "  \"\"\"\n",
    "  smoothie = SmoothingFunction().method4\n",
    "  return bleu.sentence_bleu(ref, pred, smoothing_function=smoothie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193,
     "referenced_widgets": [
      "f9d3359d93a24a58879f7e4235be9489",
      "4a948bb9a6744ccc9c594dac503d568c",
      "7eed2d37e755481c9142caa9349992a5",
      "6d821aa0244240b7a99a0c5e3775651b",
      "4830d1bd830d4b9fb88ee0f863ac8c90",
      "3ec9fde475eb47649efd59f117ffc101",
      "1783cfbd41d34cb2bdb0b9f7d736fb51",
      "491d9aeedebf47c3a6b546bc574f4c48"
     ]
    },
    "colab_type": "code",
    "id": "BO-I9qW9FVSK",
    "outputId": "10e5b7c1-2384-4e33-be77-3455f9cd793e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9d3359d93a24a58879f7e4235be9489",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "reference = []\n",
    "pred = []\n",
    "bleu_score = []\n",
    "for i in tqdm_notebook(range(14840, 14850)):\n",
    " # try :\n",
    "  decoded_sentence = translate_4_bleu(ko_list[i])[:-6]\n",
    "  reference.append(en_list[i])\n",
    "  pred.append(decoded_sentence)\n",
    "  bleu_score.append(bleu.sentence_bleu(list(map(lambda ref: ref.split(), reference)),candidate.split()))\n",
    "  # except Exception as e:\n",
    "  #   pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "NVHjBgSbjjBH",
    "outputId": "845e40b4-4636-40f4-c713-16572a8afcdb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0.6262844962765469, 0.6262844962765469, 0.6930977286178778, 0.7447819789879647, 0.7447819789879647, 0.7447819789879647, 0.7447819789879647, 0.7447819789879647, 0.7447819789879647]\n"
     ]
    }
   ],
   "source": [
    "print(bleu_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "clMQ8fSwNMds",
    "outputId": "bd5a4629-216e-4f36-8c51-18321edf62c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5266403878479265, 0.5266403878479265, 0.5266403878479265, 0.5266403878479265, 0.5266403878479265, 0.6262844962765469, 0.6262844962765469, 0.6262844962765469, 0.6262844962765469]\n"
     ]
    }
   ],
   "source": [
    "print(bleu_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "csOqUfAmNn76",
    "outputId": "7212bf6a-b2d0-4fc7-be16-e0ad782c46ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['You can see both oriental and western beauty.', 'I am more interested in you and your surroundings.', 'If you use a dehydrator, it may change the shape of it.', 'However, I feel that your words are different from your mind.', 'But it remains in our memories for good.']\n"
     ]
    }
   ],
   "source": [
    "print(reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "irfyelZINW-R",
    "outputId": "5da38991-037c-40a0-993c-a041c49fecd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['you can enjoy the market and western beauty . ', 'i have many things more than you and warmhearted . ', 'if you need a dehydrator it is a tool to use it . ', 'but you are not like your mind than what you are . ', 'but our offices is always busy together . ']\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355,
     "referenced_widgets": [
      "779146fc2e30429ba7ee11c5393c666e",
      "1c374ee3448a4104bc6fc51676cae0cb",
      "a208686fed48470daf208a8bf5246f68",
      "99c2497b5100425f9b340d29b96283b0",
      "3f961d720bda4371ac5be129de2cfa13",
      "450b26b4588f497982a537c6cb4e0348",
      "b65dd5db7f9f49759523b524133e020c",
      "fd79427e7ba54084b333a53610e68586"
     ]
    },
    "colab_type": "code",
    "id": "o3csYBXhkrKI",
    "outputId": "eb602c2f-24fc-4cea-ac3f-cde431162018"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "779146fc2e30429ba7ee11c5393c666e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15000.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 4-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "reference = []\n",
    "pred = []\n",
    "bleu_score = []\n",
    "err_cnt = 0\n",
    "for i in tqdm_notebook(range(0, 15000)):\n",
    "  try:\n",
    "    decoded_sentence = translate_4_bleu(ko_list[i])[:-6]\n",
    "    reference.append(en_list[i])\n",
    "    pred.append(decoded_sentence)\n",
    "   # bleu_score.append(bleu.sentence_bleu(list(map(lambda ref: ref.split(), reference)),candidate.split()))\n",
    "    bleu_score.append(bleu.sentence_bleu([reference[i].split()],pred[i].split()))\n",
    "\n",
    "  except KeyError:\n",
    "    err_cnt += 1\n",
    "    print(err_cnt)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "WEfjpbb5Nz5T",
    "outputId": "0b37fc82-7888-4663-8715-11071eef02b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42729303674050234\n"
     ]
    }
   ],
   "source": [
    "sum = 0\n",
    "for i in range(len(bleu_score)):\n",
    "  sum += bleu_score[i]\n",
    "\n",
    "avg = sum / (len(pred))\n",
    "print(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Rh5t9xRL-tUa",
    "outputId": "fbc06ad5-90f4-41c8-bf06-ca68a881406c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14999"
      ]
     },
     "execution_count": 90,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bleu_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HAlM3SAiAoow"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4_dC7kprAnuv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "attention_gru_seq2seq_adam_bleu.ipynb의 사본",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1783cfbd41d34cb2bdb0b9f7d736fb51": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1c374ee3448a4104bc6fc51676cae0cb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3ec9fde475eb47649efd59f117ffc101": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3f961d720bda4371ac5be129de2cfa13": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "450b26b4588f497982a537c6cb4e0348": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4830d1bd830d4b9fb88ee0f863ac8c90": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "491d9aeedebf47c3a6b546bc574f4c48": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4a948bb9a6744ccc9c594dac503d568c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6d821aa0244240b7a99a0c5e3775651b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_491d9aeedebf47c3a6b546bc574f4c48",
      "placeholder": "​",
      "style": "IPY_MODEL_1783cfbd41d34cb2bdb0b9f7d736fb51",
      "value": " 10/10 [00:31&lt;00:00,  3.12s/it]"
     }
    },
    "779146fc2e30429ba7ee11c5393c666e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a208686fed48470daf208a8bf5246f68",
       "IPY_MODEL_99c2497b5100425f9b340d29b96283b0"
      ],
      "layout": "IPY_MODEL_1c374ee3448a4104bc6fc51676cae0cb"
     }
    },
    "7eed2d37e755481c9142caa9349992a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3ec9fde475eb47649efd59f117ffc101",
      "max": 10,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4830d1bd830d4b9fb88ee0f863ac8c90",
      "value": 10
     }
    },
    "99c2497b5100425f9b340d29b96283b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fd79427e7ba54084b333a53610e68586",
      "placeholder": "​",
      "style": "IPY_MODEL_b65dd5db7f9f49759523b524133e020c",
      "value": " 15000/15000 [1:47:02&lt;00:00,  2.34it/s]"
     }
    },
    "a208686fed48470daf208a8bf5246f68": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_450b26b4588f497982a537c6cb4e0348",
      "max": 15000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3f961d720bda4371ac5be129de2cfa13",
      "value": 15000
     }
    },
    "b65dd5db7f9f49759523b524133e020c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f9d3359d93a24a58879f7e4235be9489": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7eed2d37e755481c9142caa9349992a5",
       "IPY_MODEL_6d821aa0244240b7a99a0c5e3775651b"
      ],
      "layout": "IPY_MODEL_4a948bb9a6744ccc9c594dac503d568c"
     }
    },
    "fd79427e7ba54084b333a53610e68586": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
