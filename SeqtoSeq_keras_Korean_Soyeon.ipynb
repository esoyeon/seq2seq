{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SeqtoSeq_keras_Korean_Soyeon",
      "provenance": [],
      "collapsed_sections": [
        "jaCFgfbPmQLr",
        "jrsAmqlGojuR"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QNfEeMfaKoR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        },
        "outputId": "2fca739d-0cfa-48de-ddfd-be9886396ead"
      },
      "source": [
        "!pip install konlpy"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting konlpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4MB 1.2MB/s \n",
            "\u001b[?25hCollecting JPype1>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8b/f7/a368401e630f0e390dd0e62c39fb928e5b23741b53c2360ee7d376660927/JPype1-1.0.2-cp36-cp36m-manylinux2010_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 44.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
            "Collecting tweepy>=3.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/bb/7c/99d51f80f3b77b107ebae2634108717362c059a41384a1810d13e2429a81/tweepy-3.9.0-py2.py3-none-any.whl\n",
            "Collecting beautifulsoup4==4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 13.4MB/s \n",
            "\u001b[?25hCollecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.18.5)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Installing collected packages: JPype1, tweepy, beautifulsoup4, colorama, konlpy\n",
            "  Found existing installation: tweepy 3.6.0\n",
            "    Uninstalling tweepy-3.6.0:\n",
            "      Successfully uninstalled tweepy-3.6.0\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed JPype1-1.0.2 beautifulsoup4-4.6.0 colorama-0.4.3 konlpy-0.5.2 tweepy-3.9.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5I8QdfbhnAA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import re\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import pandas as pd\n",
        "import os\n",
        "import unicodedata\n",
        "import urllib3\n",
        "import zipfile"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LABpcIl4h36L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "outputId": "e1464c21-9ae8-4433-f465-19ad5e485cd9"
      },
      "source": [
        "text = pd.read_excel('/content/kor.xlsx', encoding='CP949')\n",
        "text"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mid_sid</th>\n",
              "      <th>ko</th>\n",
              "      <th>en</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>나는 매일 저녁 배트를 만나러 다락방으로 가요.</td>\n",
              "      <td>I go to the attic every evening to meet Bat.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>선생님 이문장이 이해가 안 가요.</td>\n",
              "      <td>Sir, I don't understand this sentence here.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>컴퓨터를 시작하면 시간이 너무 빠르게 가요.</td>\n",
              "      <td>Time flies when you start using the computer.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>나는 오늘 자정에 한국으로 돌아 가요.</td>\n",
              "      <td>I'm going back to Korea today at midnight.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>나는 일어나자마자 화장실에 가요.</td>\n",
              "      <td>I go to bathroom as soon as I wake up.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74995</th>\n",
              "      <td>74996</td>\n",
              "      <td>나의 고민은 학교가 멀어서 통학하기 힘들어.</td>\n",
              "      <td>My worry is commuting to school because it's t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74996</th>\n",
              "      <td>74997</td>\n",
              "      <td>난 지금 내고양이때문에 충분히 힘들어.</td>\n",
              "      <td>I am going under enough difficulties because o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74997</th>\n",
              "      <td>74998</td>\n",
              "      <td>나와 대화가 어려운 것이 많이 힘들어?</td>\n",
              "      <td>Is having difficulties in talking with me too ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74998</th>\n",
              "      <td>74999</td>\n",
              "      <td>하루에 한번 연락하는게 그렇게 힘들어?</td>\n",
              "      <td>Is it that difficult to call once a day?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74999</th>\n",
              "      <td>75000</td>\n",
              "      <td>어린 아이들이 스포츠를 즐기기엔 많이 힘들죠.</td>\n",
              "      <td>It is difficult for young children to enjoy sp...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>75000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       mid_sid  ...                                                 en\n",
              "0            1  ...       I go to the attic every evening to meet Bat.\n",
              "1            2  ...        Sir, I don't understand this sentence here.\n",
              "2            3  ...      Time flies when you start using the computer.\n",
              "3            4  ...         I'm going back to Korea today at midnight.\n",
              "4            5  ...             I go to bathroom as soon as I wake up.\n",
              "...        ...  ...                                                ...\n",
              "74995    74996  ...  My worry is commuting to school because it's t...\n",
              "74996    74997  ...  I am going under enough difficulties because o...\n",
              "74997    74998  ...  Is having difficulties in talking with me too ...\n",
              "74998    74999  ...           Is it that difficult to call once a day?\n",
              "74999    75000  ...  It is difficult for young children to enjoy sp...\n",
              "\n",
              "[75000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7lC4kB1ak37",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcBtawu9h-Mh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a777a1c6-2d86-47eb-e63c-141c4a296059"
      },
      "source": [
        "df = text[['ko','en']]\n",
        "\n",
        "df.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(75000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viUcaT8jYzWT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "b7db5269-1db7-4f82-db38-2879cc3efdfb"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ko</th>\n",
              "      <th>en</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>나는 매일 저녁 배트를 만나러 다락방으로 가요.</td>\n",
              "      <td>I go to the attic every evening to meet Bat.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>선생님 이문장이 이해가 안 가요.</td>\n",
              "      <td>Sir, I don't understand this sentence here.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>컴퓨터를 시작하면 시간이 너무 빠르게 가요.</td>\n",
              "      <td>Time flies when you start using the computer.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>나는 오늘 자정에 한국으로 돌아 가요.</td>\n",
              "      <td>I'm going back to Korea today at midnight.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>나는 일어나자마자 화장실에 가요.</td>\n",
              "      <td>I go to bathroom as soon as I wake up.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           ko                                             en\n",
              "0  나는 매일 저녁 배트를 만나러 다락방으로 가요.   I go to the attic every evening to meet Bat.\n",
              "1          선생님 이문장이 이해가 안 가요.    Sir, I don't understand this sentence here.\n",
              "2    컴퓨터를 시작하면 시간이 너무 빠르게 가요.  Time flies when you start using the computer.\n",
              "3       나는 오늘 자정에 한국으로 돌아 가요.     I'm going back to Korea today at midnight.\n",
              "4          나는 일어나자마자 화장실에 가요.         I go to bathroom as soon as I wake up."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTGz8ro8h_9D",
        "colab_type": "text"
      },
      "source": [
        "## 전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtcrwzYHihOY",
        "colab_type": "text"
      },
      "source": [
        "유니코드(Unicode) 문자열은 문자를 Unicode로 취급하기 때문에 영어나 한국어등의 ASCII 문자로 되어있어도 한 개 문자를 하나씩 다룹니다.\n",
        "\n",
        "즉, 일반 문자열은 바이트 단위로 처리 하지만, 유니코드 문자열에서는 문자 단위로 처리하게 됩니다.\n",
        "\n",
        "한글을 글자 깨짐 없이 사용하고 싶은 경우에는 유니코드 문자열을 사용하면 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QD1tTgAiiBXi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unicode_to_ascii(s): \n",
        "  return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "      if unicodedata.category(c) != 'Mn')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0aTBhVeiEOe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_sentence(sent):\n",
        "    # 위에서 구현한 함수를 내부적으로 호출\n",
        "    # sent = unicode_to_ascii()\n",
        "\n",
        "    # 단어와 구두점 사이에 공백을 만듭니다.\n",
        "    # Ex) \"he is a boy.\" => \"he is a boy .\"\n",
        "    sent = re.sub(r\"([?.!,¿])\", r\" \\1\", sent)\n",
        "\n",
        "    # (a-z, A-Z, \".\", \"?\", \"!\", \",\") 이들을 제외하고는 전부 공백으로 변환합니다.\n",
        "    sent = re.sub(r\"[^a-zA-Zㄱ-ㅎㅏ-ㅣ가-힣!.?]+\", r\" \", sent)\n",
        "\n",
        "    sent = re.sub(r\"\\s+\", \" \", sent)\n",
        "    return sent"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaLb5l-yiLhw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "55d6d8c2-c560-49ab-d1a3-b95b3ab7d03e"
      },
      "source": [
        "# 전처리 테스트\n",
        "# 문자열 앞에 [u]또는 [U]를 붙여주면 유니코드 문자열이 됩니다.\n",
        "\n",
        "kor_sent1 = u\"저녁 먹었어?\"\n",
        "eng_sent1 = u\"Have you had dinner?\"\n",
        "\n",
        "print(preprocess_sentence(eng_sent1))\n",
        "print(preprocess_sentence(kor_sent1))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Have you had dinner ?\n",
            "저녁 먹었어 ?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zfjp70HNiNGR",
        "colab_type": "text"
      },
      "source": [
        "- 전체 데이터에서 33,000개의 샘플만 불러오되, 모든 전처리를 수행하는 함수를 만듭니다.   \n",
        "- 또한 훈련 과정에서 교사 강요(Teacher Forcing)을 사용할 예정이므로, 훈련 시 사용할 디코더의 입력 시퀀스와 실제값에 해당되는 출력 시퀀스를 따로 분리하여 저장합니다.   \n",
        "- 입력 시퀀스에는 시작을 의미하는 토큰인 \\<sos\\>를 추가하고, 출력 시퀀스에는 종료를 의미하는 토큰인 \\<eos\\>를 추가합니다  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qHeqtSjf4E-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "87922b5c-e656-46a2-b03b-605bfe72f2ac"
      },
      "source": [
        "len(df)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "75000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35ARgUb4i7FF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_preprocessed_data(df):\n",
        "    encoder_input, decoder_input, decoder_target = [], [], []\n",
        "    for i in range(len(df)):\n",
        "      src_line = df.iloc[i][0].strip()\n",
        "      tar_line = df.iloc[i][1].strip()\n",
        "\n",
        "      # source 데이터 전처리\n",
        "      src_line_input = [w for w in preprocess_sentence(src_line).split()]\n",
        "\n",
        "      # target 데이터 전처리\n",
        "      tar_line = preprocess_sentence(tar_line)\n",
        "      tar_line_input = [w for w in (\"<sos> \" + tar_line).split()]\n",
        "      tar_line_target = [w for w in (tar_line + \" <eos>\").split()]\n",
        "\n",
        "      encoder_input.append(src_line_input[::-1])\n",
        "      decoder_input.append(tar_line_input)\n",
        "      decoder_target.append(tar_line_target)\n",
        "\n",
        "      # if i == num_samples - 1:\n",
        "      #     break\n",
        "\n",
        "    return encoder_input, decoder_input, decoder_target"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5SzBBe7jEm2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encoder_input, decoder_input, decoder_target\n",
        "sents_kor_in, sents_eng_in, sents_eng_out = load_preprocessed_data(df)"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ar1600phv-1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "fbe5e1e8-d666-4567-d846-00149536a6de"
      },
      "source": [
        "print(sents_kor_in[-5:])\n",
        "print(sents_eng_in[-5:])\n",
        "print(sents_eng_out[-5:])"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['.', '힘들어', '통학하기', '멀어서', '학교가', '고민은', '나의'], ['.', '힘들어', '충분히', '내고양이때문에', '지금', '난'], ['?', '힘들어', '많이', '것이', '어려운', '대화가', '나와'], ['?', '힘들어', '그렇게', '연락하는게', '한번', '하루에'], ['.', '힘들죠', '많이', '즐기기엔', '스포츠를', '아이들이', '어린']]\n",
            "[['<sos>', 'My', 'worry', 'is', 'commuting', 'to', 'school', 'because', 'it', 's', 'too', 'far', '.'], ['<sos>', 'I', 'am', 'going', 'under', 'enough', 'difficulties', 'because', 'of', 'my', 'cat', '.'], ['<sos>', 'Is', 'having', 'difficulties', 'in', 'talking', 'with', 'me', 'too', 'hard', 'for', 'you', '?'], ['<sos>', 'Is', 'it', 'that', 'difficult', 'to', 'call', 'once', 'a', 'day', '?'], ['<sos>', 'It', 'is', 'difficult', 'for', 'young', 'children', 'to', 'enjoy', 'sports', '.']]\n",
            "[['My', 'worry', 'is', 'commuting', 'to', 'school', 'because', 'it', 's', 'too', 'far', '.', '<eos>'], ['I', 'am', 'going', 'under', 'enough', 'difficulties', 'because', 'of', 'my', 'cat', '.', '<eos>'], ['Is', 'having', 'difficulties', 'in', 'talking', 'with', 'me', 'too', 'hard', 'for', 'you', '?', '<eos>'], ['Is', 'it', 'that', 'difficult', 'to', 'call', 'once', 'a', 'day', '?', '<eos>'], ['It', 'is', 'difficult', 'for', 'young', 'children', 'to', 'enjoy', 'sports', '.', '<eos>']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTcZzgo-kWZG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 인코딩\n",
        "tokenizer_kor = Tokenizer()\n",
        "tokenizer_kor.fit_on_texts(sents_kor_in)\n",
        "encoder_input = tokenizer_kor.texts_to_sequences(sents_kor_in)\n",
        "\n",
        "tokenizer_eng = Tokenizer(filters=\"\", lower=True)\n",
        "tokenizer_eng.fit_on_texts(sents_eng_in)\n",
        "tokenizer_eng.fit_on_texts(sents_eng_out)\n",
        "decoder_input = tokenizer_eng.texts_to_sequences(sents_eng_in)\n",
        "decoder_target = tokenizer_eng.texts_to_sequences(sents_eng_out)"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WYeBydik31E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 패딩\n",
        "encoder_input = pad_sequences(encoder_input, padding=\"post\")\n",
        "decoder_input = pad_sequences(decoder_input, padding=\"post\")\n",
        "decoder_target = pad_sequences(decoder_target, padding=\"post\")"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnqOY1ySk6R9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fe2dd2cf-66a2-4d46-d6e7-383f2ef146b8"
      },
      "source": [
        "encoder_input.shape, decoder_input.shape, decoder_target.shape"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((75000, 15), (75000, 19), (75000, 19))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPMBqSX1lC6v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dfcf2674-128a-4652-a979-88e139073370"
      },
      "source": [
        "src_vocab_size = len(tokenizer_kor.word_index) + 1\n",
        "tar_vocab_size = len(tokenizer_eng.word_index) + 1\n",
        "print(\"한국어 단어 집합의 크기 : {:d}, 영어 단어 집합의 크기 : {:d}\".format(src_vocab_size, tar_vocab_size))"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "한국어 단어 집합의 크기 : 85237, 영어 단어 집합의 크기 : 19285\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjRNkAR1SIKC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "fb00cc37-6fe0-4704-b30d-cd44c85a16d5"
      },
      "source": [
        "encoder_input"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[    1,   211, 29411, ...,     0,     0,     0],\n",
              "       [    1,   211,    72, ...,     0,     0,     0],\n",
              "       [    1,   211,   977, ...,     0,     0,     0],\n",
              "       ...,\n",
              "       [    2,  1307,    25, ...,     0,     0,     0],\n",
              "       [    2,  1307,   232, ...,     0,     0,     0],\n",
              "       [    1, 85236,    25, ...,     0,     0,     0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGBrDW73lNfr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "src_to_index = tokenizer_kor.word_index\n",
        "index_to_src = tokenizer_kor.index_word # 훈련 후 결과 비교할 때 사용\n",
        "\n",
        "tar_to_index = tokenizer_eng.word_index # 훈련 후 예측 과정에서 사용\n",
        "index_to_tar = tokenizer_eng.index_word # 훈련 후 결과 비교할 때 사용"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09io52LElVV3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d1e8d57e-fc74-4be3-d061-48910a5d850b"
      },
      "source": [
        "indices = np.arange(encoder_input.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "print(indices)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[56209 53138  4299 ... 20058 38635 10770]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFRwXsBAlj_D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_input = encoder_input[indices]\n",
        "decoder_input = decoder_input[indices]\n",
        "decoder_target = decoder_target[indices]"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eME6EYkfllYJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "82d8077c-fc30-4c99-dfad-66590f1962af"
      },
      "source": [
        "encoder_input[30997], decoder_input[30997], decoder_target[30997]"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([    1, 43566,  7599,  9645, 43567,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0], dtype=int32),\n",
              " array([    2,     8,  3198,    13,  5983,     9,     8,  1603,    17,\n",
              "         7547, 12772,    13,    61,     1,     0,     0,     0,     0,\n",
              "            0], dtype=int32),\n",
              " array([    8,  3198,    13,  5983,     9,     8,  1603,    17,  7547,\n",
              "        12772,    13,    61,     1,     3,     0,     0,     0,     0,\n",
              "            0], dtype=int32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwDw4wtQl7oG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f7af52cd-de65-4fbf-c39e-2ea315755225"
      },
      "source": [
        "n_of_val = int(len(df)*0.1)\n",
        "print(n_of_val)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfLOpFIwmL5T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_input_train = encoder_input[:-n_of_val]\n",
        "decoder_input_train = decoder_input[:-n_of_val]\n",
        "decoder_target_train = decoder_target[:-n_of_val]\n",
        "\n",
        "encoder_input_test = encoder_input[-n_of_val:]\n",
        "decoder_input_test = decoder_input[-n_of_val:]\n",
        "decoder_target_test = decoder_target[-n_of_val:]"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfS_TRG0mNyy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "03780e57-7b3d-44b9-ccb0-724d1b8d3e54"
      },
      "source": [
        "print(encoder_input_train.shape)\n",
        "print(decoder_input_train.shape)\n",
        "print(decoder_target_train.shape)\n",
        "print(encoder_input_test.shape)\n",
        "print(decoder_input_test.shape)\n",
        "print(decoder_target_test.shape)"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(67500, 15)\n",
            "(67500, 19)\n",
            "(67500, 19)\n",
            "(7500, 15)\n",
            "(7500, 19)\n",
            "(7500, 19)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqfRWlQ3SExd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "a5c76ac1-981f-4936-9230-3f9d76ab1aed"
      },
      "source": [
        "encoder_input_train"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[    1,    24,   558, ...,     0,     0,     0],\n",
              "       [    1,  4353,  1552, ...,     0,     0,     0],\n",
              "       [    1,    33,    95, ...,     0,     0,     0],\n",
              "       ...,\n",
              "       [    2,  2555, 71841, ...,     0,     0,     0],\n",
              "       [    1,  3329,   569, ...,     0,     0,     0],\n",
              "       [    1,  2439, 51934, ...,     0,     0,     0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaCFgfbPmQLr",
        "colab_type": "text"
      },
      "source": [
        "## 기계 번역기 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7aTnvt8me5m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_Bv_49LWnVP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0027bf32-7c7d-4373-cd7d-4e8e6676b6ef"
      },
      "source": [
        "src_vocab_size"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "85237"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnK_9Hxfmggb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "latent_dim = 100"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGiP70Egmi8i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 인코더\n",
        "encoder_inputs = Input(shape=(None,))\n",
        "enc_emb =  Embedding(src_vocab_size, latent_dim)(encoder_inputs) # 임베딩 층\n",
        "enc_masking = Masking(mask_value=0.0)(enc_emb) # 패딩 0은 연산에서 제외\n",
        "encoder_lstm = LSTM(latent_dim, return_state=True, return_sequence=True) # 상태값 리턴을 위해 return_state는 True\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(enc_masking) # 은닉 상태와 셀 상태를 리턴\n",
        "encoder_states = [state_h, state_c] # 인코더의 은닉 상태와 셀 상태를 저장"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sySTJ-GEnWVp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 디코더\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "dec_emb_layer = Embedding(tar_vocab_size, latent_dim) # 임베딩 층\n",
        "dec_emb = dec_emb_layer(decoder_inputs) # 패딩 0은 연산에서 제외\n",
        "dec_masking = Masking(mask_value=0.0)(dec_emb)\n",
        "\n",
        "# 상태값 리턴을 위해 return_state는 True, 모든 시점에 대해서 단어를 예측하기 위해 return_sequences는 True\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True) \n",
        "\n",
        "# 인코더의 은닉 상태를 초기 은닉 상태(initial_state)로 사용\n",
        "decoder_outputs, _, _ = decoder_lstm(dec_masking,\n",
        "                                     initial_state=encoder_states)\n",
        "\n",
        "# 모든 시점의 결과에 대해서 소프트맥스 함수를 사용한 출력층을 통해 단어 예측\n",
        "decoder_dense = Dense(tar_vocab_size, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DecHMA09oPLl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2neJEUFZoRHY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# learning rate 조절하기 \n",
        "def scheduler(epoch, lr):\n",
        "  if epoch < 5:\n",
        "    return lr\n",
        "  else:\n",
        "    return lr/2*(epoch-5)"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFZS94lveHcB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.optimizers import SGD\n",
        "epochs = 50\n",
        "learning_rate = 0.7\n",
        "model.compile(SGD(learning_rate=0.75), loss='sparse_categorical_crossentropy', metrics = ['acc'])"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnOOHdb5Xcre",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
        "callbacks = [\n",
        "             EarlyStopping(monitor ='val_acc', patience = 3),\n",
        "             LearningRateScheduler(scheduler)\n",
        "             ]"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rk7F0CtLoh7T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "c7234f5a-ed81-4a9c-f260-678304cbd86f"
      },
      "source": [
        "model.fit(x = [encoder_input_train, decoder_input_train], y = decoder_target_train, \\\n",
        "          validation_data = ([encoder_input_test, decoder_input_test], decoder_target_test),\n",
        "          batch_size = 128, epochs = 30, callbacks = callbacks)"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "528/528 [==============================] - 58s 110ms/step - loss: 1.9493 - acc: 0.6717 - val_loss: 2.3719 - val_acc: 0.6286\n",
            "Epoch 2/30\n",
            "528/528 [==============================] - 56s 107ms/step - loss: 1.7748 - acc: 0.6971 - val_loss: 2.4344 - val_acc: 0.6201\n",
            "Epoch 3/30\n",
            "528/528 [==============================] - 56s 107ms/step - loss: 1.7224 - acc: 0.7052 - val_loss: 2.4109 - val_acc: 0.6252\n",
            "Epoch 4/30\n",
            "528/528 [==============================] - 56s 107ms/step - loss: 1.6909 - acc: 0.7105 - val_loss: 2.4521 - val_acc: 0.6220\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc615fa5320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrsAmqlGojuR",
        "colab_type": "text"
      },
      "source": [
        "## seq2seq 기계 번역기 동작시키기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFTc0cV-uBFS",
        "colab_type": "text"
      },
      "source": [
        "keras model의 뜻"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mC4_XWo7uCrq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "e264d5b6-4f71-4086-8ab9-7d1e358413db"
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense\n",
        "\n",
        "a = Input(shape=(32,))\n",
        "b = Dense(32)(a)\n",
        "model = Model(inputs=a, outputs=b)\n",
        "\n",
        "model.summary()\n",
        "# input 'a'와, output 'b'를 구성하기 위한 모든 layer를 자동으로 구성함"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_12 (InputLayer)        [(None, 32)]              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 32)                1056      \n",
            "=================================================================\n",
            "Total params: 1,056\n",
            "Trainable params: 1,056\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdkSl6AmopyM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "e1974b11-bbc9-41f3-b940-f7dd7b573954"
      },
      "source": [
        "# 인코더\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "encoder_model.summary()"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_10 (InputLayer)        [(None, None)]            0         \n",
            "_________________________________________________________________\n",
            "embedding_4 (Embedding)      (None, None, 100)         8523700   \n",
            "_________________________________________________________________\n",
            "masking_4 (Masking)          (None, None, 100)         0         \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                [(None, 100), (None, 100) 80400     \n",
            "=================================================================\n",
            "Total params: 8,604,100\n",
            "Trainable params: 8,604,100\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNLPvMRzr7oa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # 디코더\n",
        "# decoder_inputs = Input(shape=(None,))\n",
        "# dec_emb_layer = Embedding(tar_vocab_size, latent_dim) # 임베딩 층\n",
        "# dec_emb = dec_emb_layer(decoder_inputs) # 패딩 0은 연산에서 제외\n",
        "# dec_masking = Masking(mask_value=0.0)(dec_emb)\n",
        "\n",
        "# # 상태값 리턴을 위해 return_state는 True, 모든 시점에 대해서 단어를 예측하기 위해 return_sequences는 True\n",
        "# decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True) \n",
        "\n",
        "# # 인코더의 은닉 상태를 초기 은닉 상태(initial_state)로 사용\n",
        "# decoder_outputs, _, _ = decoder_lstm(dec_masking,\n",
        "#                                      initial_state=encoder_states)\n",
        "\n",
        "# # 모든 시점의 결과에 대해서 소프트맥스 함수를 사용한 출력층을 통해 단어 예측\n",
        "# decoder_dense = Dense(tar_vocab_size, activation='softmax')\n",
        "# decoder_outputs = decoder_dense(decoder_outputs)"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8n2JmmrqOJC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 디코더\n",
        "# 이전 시점의 상태를 보관할 텐서\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "# 훈련 때 사용했던 임베딩 층을 재사용\n",
        "dec_emb2= dec_emb_layer(decoder_inputs)\n",
        "\n",
        "# 다음 단어 예측을 위해 이전 시점의 상태를 현 시점의 초기 상태로 사용\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
        "decoder_states2 = [state_h2, state_c2]\n",
        "\n",
        "# 모든 시점에 대해서 단어 예측\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2)"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYB4omDiqRMY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs2] + decoder_states2)"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XzrgpalqRzL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "4b72b102-ed60-4bdb-9cc2-02a42db92a8a"
      },
      "source": [
        "decoder_model.summary()"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_17\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_11 (InputLayer)           [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_5 (Embedding)         (None, None, 100)    1928500     input_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "input_13 (InputLayer)           [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_14 (InputLayer)           [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_5 (LSTM)                   [(None, None, 100),  80400       embedding_5[1][0]                \n",
            "                                                                 input_13[0][0]                   \n",
            "                                                                 input_14[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, None, 19285)  1947785     lstm_5[1][0]                     \n",
            "==================================================================================================\n",
            "Total params: 3,956,685\n",
            "Trainable params: 3,956,685\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2po8QN4rWyh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # 입력으로부터 인코더의 상태를 얻음\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    # <SOS>에 해당하는 정수 생성\n",
        "    target_seq = np.zeros((1,1))\n",
        "    target_seq[0, 0] = tar_to_index['<sos>']\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "\n",
        "    # stop_condition이 True가 될 때까지 루프 반복\n",
        "    # 구현의 간소화를 위해서 이 함수는 배치 크기를 1로 가정합니다.\n",
        "    while not stop_condition:\n",
        "        # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "        # 예측 결과를 단어로 변환\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = index_to_tar[sampled_token_index]\n",
        "\n",
        "         # 현재 시점의 예측 단어를 예측 문장에 추가\n",
        "        decoded_sentence += ' '+sampled_char\n",
        "\n",
        "        # <eos>에 도달하거나 정해진 길이를 넘으면 중단.\n",
        "        if (sampled_char == '<eos>' or\n",
        "           len(decoded_sentence) > 50):\n",
        "            stop_condition = True\n",
        "\n",
        "        # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcGLZhsAunlc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
        "def seq2src(input_seq):\n",
        "    temp=''\n",
        "    for i in input_seq:\n",
        "        if (i!=0):\n",
        "            temp = temp + index_to_src[i]+' '\n",
        "    return temp\n",
        "\n",
        "# 번역문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
        "def seq2tar(input_seq):\n",
        "    temp=''\n",
        "    for i in input_seq:\n",
        "        if ((i!=0 and i!=tar_to_index['<sos>']) and i!=tar_to_index['<eos>']):\n",
        "            temp = temp + index_to_tar[i] + ' '\n",
        "    return temp"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPvMn_aPu0-a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "outputId": "45b8db24-f3eb-40a0-e218-148c0361e39c"
      },
      "source": [
        "for seq_index in [3,50,100,300,1001]:\n",
        "  input_seq = encoder_input_train[seq_index: seq_index + 1]\n",
        "  decoded_sentence = decode_sequence(input_seq)\n",
        "\n",
        "  print(\"원문 : \",seq2src(encoder_input_train[seq_index][::-1]))\n",
        "  print(\"번역문 :\",seq2tar(decoder_input_train[seq_index]))\n",
        "  print(\"예측문 :\",decoded_sentence[:-5])\n",
        "  print(\"\\n\")"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "원문 :  그리고 국물에는 얼음이 들어가있어서 시원했어요 . \n",
            "번역문 : and the soup was so cooling because it had ice in it . \n",
            "예측문 :  and it was not easy but it s a little bit of \n",
            "\n",
            "\n",
            "원문 :  결국 이 프로젝트는 아이들에게 트라우마가 돼요 . \n",
            "번역문 : eventually this project becomes trauma for the children . \n",
            "예측문 :  this lot of addition should make our own leas\n",
            "\n",
            "\n",
            "원문 :  타미가 저를 좋아하는지는 중요하지 않아요 . \n",
            "번역문 : whether tammy likes me is not the point . \n",
            "예측문 :  not true is not the same as a gift . \n",
            "\n",
            "\n",
            "원문 :  오히려 내 영어 실력이 부끄러워지는 순간이에요 . \n",
            "번역문 : it was the moment my english skill rather felt embarrassing . \n",
            "예측문 :  it was a good memory that i m afraid of good mem\n",
            "\n",
            "\n",
            "원문 :  한국의 은행으로부터 돈을 찾는데 필요해요 . \n",
            "번역문 : it is needed to withdraw money from banks in korea . \n",
            "예측문 :  it is necessary to use your own country s own . \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUMl-qEdu_ck",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}